BOND Codebase Documentation
================================================================================
Generated: 2025-08-31 01:29:47
Source Directory: /Users/rajlq7/Downloads/Terms/BOND/bond
Output File: /Users/rajlq7/Downloads/Terms/BOND/Miscellaneous/bond_documentation.txt
================================================================================

DIRECTORY TREE STRUCTURE
--------------------------------------------------------------------------------
├── __init__.py
├── abbrev.py
├── cli.py
├── config.py
├── field_guidance.py
├── fusion.py
├── fusion_weights.py
├── graph_utils.py
├── logger.py
├── models.py
├── pipeline.py
├── prompts.py
├── providers.py
├── rerank.py
├── retrieval
│     ├── __init__.py
│     ├── bm25_sqlite.py
│     └── faiss_store.py

├── rules.py
├── runtime_env.py
├── schema_policies.py
├── server.py
└── validate_signature.py

================================================================================

FILE CONTENTS
--------------------------------------------------------------------------------

File: /Users/rajlq7/Downloads/Terms/BOND/bond/__init__.py
Size: 8 lines
================================================================================
   1: from .runtime_env import configure_runtime
   2: configure_runtime()
   3: 
   4: __version__ = "0.2.0"
   5: 
   6: from .pipeline import BondMatcher
   7: 
   8: __all__ = ["BondMatcher", "__version__"]

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/abbrev.py
Size: 62 lines
================================================================================
   1: import os
   2: import json
   3: import re
   4: from typing import Dict, List, Tuple
   5: 
   6: 
   7: class AbbreviationExpander:
   8:     """
   9:     Loads field-scoped abbreviations from assets/abbreviations.json and applies
  10:     alphanumeric-boundary replacements so tokens adjacent to '_' or '+' match.
  11:     """
  12: 
  13:     def __init__(self, assets_path: str):
  14:         self._pats: Dict[str, List[Tuple[re.Pattern[str], str]]] = {}
  15:         abbr_path = os.path.join(assets_path, "abbreviations.json")
  16:         if not os.path.exists(abbr_path):
  17:             return
  18:         try:
  19:             with open(abbr_path, "r", encoding="utf-8") as f:
  20:                 data = json.load(f)
  21:         except Exception:
  22:             return
  23: 
  24:         def compile_map(m: Dict[str, object]) -> List[Tuple[re.Pattern[str], str]]:
  25:             pats: List[Tuple[re.Pattern[str], str]] = []
  26:             for k, v in m.items():
  27:                 if not isinstance(k, str):
  28:                     continue
  29:                 if isinstance(v, list) and v:
  30:                     repl = str(v[0])
  31:                 elif isinstance(v, str):
  32:                     repl = v
  33:                 else:
  34:                     continue
  35:                 # (?<![A-Za-z0-9])token(?![A-Za-z0-9]) to avoid splitting on '_' or '+'
  36:                 pat = re.compile(rf"(?<![A-Za-z0-9]){re.escape(k)}(?![A-Za-z0-9])", re.IGNORECASE)
  37:                 pats.append((pat, repl))
  38:             return pats
  39: 
  40:         if isinstance(data, dict):
  41:             flat_entries: Dict[str, object] = {}
  42:             for top_k, top_v in data.items():
  43:                 if isinstance(top_v, dict):
  44:                     self._pats[top_k.lower()] = compile_map(top_v)
  45:                 else:
  46:                     flat_entries[top_k] = top_v
  47:             if flat_entries:
  48:                 self._pats.setdefault("global", []).extend(compile_map(flat_entries))
  49: 
  50:     def expand(self, text: str, field_name: str | None) -> str:
  51:         if not text or not self._pats:
  52:             return text
  53:         out = text
  54:         keys: List[str] = []
  55:         if field_name:
  56:             keys.append(field_name.lower())
  57:         keys.extend(["*", "global"])  # optional global sections
  58:         for key in keys:
  59:             for pat, repl in self._pats.get(key, []):
  60:                 out = pat.sub(repl, out)
  61:         return out
  62: 

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/cli.py
Size: 140 lines
================================================================================
   1: import argparse
   2: import json
   3: from .runtime_env import configure_runtime
   4: import os
   5: from .config import BondSettings
   6: from .pipeline import BondMatcher
   7: from .rules import normalize_organism
   8: 
   9: def main():
  10:     # Configure runtime before importing heavy libs used downstream
  11:     configure_runtime()
  12:     # Default to WARNING logs for CLI unless user overrides
  13:     os.environ.setdefault("BOND_LOG_LEVEL", "WARNING")
  14:     p = argparse.ArgumentParser(description="BOND: Biomedical Ontology Normalization and Disambiguation")
  15:     p.add_argument("--query", required=True, help="The term to harmonize.")
  16:     p.add_argument("--field", dest="field_name", required=True, help="Schema field name (e.g., cell_type, tissue, disease)")
  17:     p.add_argument("--tissue", required=True, help="Tissue/organ context (e.g., lung, brain)")
  18:     p.add_argument("--organism", required=True, help="Organism (canonical name; e.g., 'Homo sapiens')")
  19:     p.add_argument("--embed", default=None, help="Override embedding model (auto-detected: st:/litellm/http)")
  20:     p.add_argument("--n_expansions", type=int, default=None, help="Number of query expansions to generate")
  21:     p.add_argument("--topk_final", type=int, default=None, help="Number of final results to return")
  22:     p.add_argument("--num_choices", type=int, default=None, help="Also return N alternatives in addition to the chosen")
  23:     p.add_argument("--topk_exact", type=int, default=None, help="Override top-k for exact match retrieval")
  24:     p.add_argument("--topk_bm25", type=int, default=None, help="Override top-k for BM25 retrieval")
  25:     p.add_argument("--topk_dense", type=int, default=None, help="Override top-k for vector retrieval")
  26:     p.add_argument("--rrf_k", type=float, default=None, help="Override RRF k parameter")
  27:     p.add_argument("--exact_only", action="store_true", help="Exact channel only (skip BM25/FAISS)")
  28:     p.add_argument("--graph_depth", type=int, default=None, help="Graph expansion depth (0 disables)")
  29:     p.add_argument("--rerank_after_graph", action="store_true", help="Run second RRF after graph expansion")
  30:     p.add_argument("--return_trace", action="store_true", help="Include detailed trace information in output")
  31:     p.add_argument("--verbose", action="store_true", help="Print expanded queries and top-k candidates to stderr")
  32:     # No manual ontology restriction; field/organism scoping is automatic
  33:     args = p.parse_args()
  34: 
  35:     cfg = BondSettings()
  36:     if args.embed:
  37:         cfg.embed_model = args.embed
  38: 
  39:     # Validate organism and field (canonical lists only)
  40:     from .schema_policies import supported_organisms, supported_fields
  41:     if args.organism not in supported_organisms():
  42:         import sys
  43:         opts = ", ".join(supported_organisms())
  44:         print(f"Error: Unsupported organism '{args.organism}'. Supported: {opts}", file=sys.stderr)
  45:         sys.exit(2)
  46:     if args.field_name.lower() not in supported_fields():
  47:         import sys
  48:         opts = ", ".join(supported_fields())
  49:         print(f"Error: Unsupported field '{args.field_name}'. Supported: {opts}", file=sys.stderr)
  50:         sys.exit(2)
  51: 
  52:     # Normalize organism for CLI friendliness
  53:     if args.organism:
  54:         args.organism = normalize_organism(args.organism) or args.organism
  55:     # Treat common null-like tissues as None
  56:     tval = (args.tissue or "").strip().lower()
  57:     if tval in {"", "null", "none", "n/a", "na"}:
  58:         args.tissue = None
  59: 
  60:     matcher = BondMatcher(cfg)
  61:     result = matcher.query(
  62:         args.query,
  63:         field_name=args.field_name,
  64:         organism=args.organism,
  65:         tissue=args.tissue,
  66:         n_expansions=args.n_expansions,
  67:         topk_final=args.topk_final,
  68:         num_choices=args.num_choices,
  69:         topk_exact=args.topk_exact,
  70:         topk_bm25=args.topk_bm25,
  71:         topk_dense=args.topk_dense,
  72:         rrf_k=args.rrf_k,
  73:         exact_only=args.exact_only,
  74:         graph_depth=args.graph_depth,
  75:         rerank_after_graph=args.rerank_after_graph,
  76:         return_trace=args.return_trace or args.verbose,
  77:     )
  78:     if args.verbose and "trace" in result:
  79:         import sys
  80:         trace = result["trace"]
  81:         print("\n[verbose] expansions:", file=sys.stderr)
  82:         for e in trace.get("expansions", []):
  83:             print(f"  - {e}", file=sys.stderr)
  84:         print("[verbose] fusion top-k:", file=sys.stderr)
  85:         for fid, score in trace.get("fusion", []):
  86:             print(f"  - {fid} (score={score:.6f})", file=sys.stderr)
  87: 
  88:     # Output formatting per new spec
  89:     def _chosen_clean(ch):
  90:         if not ch:
  91:             return None
  92:         ordered = {
  93:             "id": ch.get("id"),
  94:             "label": ch.get("label"),
  95:             "definition": ch.get("definition"),
  96:             "source": ch.get("source"),
  97:             "iri": ch.get("iri"),
  98:             "synonyms_exact": ch.get("synonyms_exact"),
  99:             "synonyms_related": ch.get("synonyms_related"),
 100:             "synonyms_broad": ch.get("synonyms_broad"),
 101:             "synonyms_generic": ch.get("synonyms_generic"),
 102:             "alt_ids": ch.get("alt_ids"),
 103:             "xrefs": ch.get("xrefs"),
 104:             "namespace": ch.get("namespace"),
 105:             "subsets": ch.get("subsets"),
 106:             "comments": ch.get("comments"),
 107:             "parents_is_a": ch.get("parents_is_a"),
 108:             "abstracts": ch.get("abstracts"),
 109:         }
 110:         return ordered
 111: 
 112:     chosen = _chosen_clean(result.get("chosen"))
 113:     if args.verbose or args.return_trace:
 114:         out = {
 115:             "expansions": result.get("trace", {}).get("expansions", []),
 116:             "context_terms": result.get("trace", {}).get("context_terms", []),
 117:             "fusion_top_k": result.get("trace", {}).get("fusion", []),
 118:             "trace": result.get("trace", {}),
 119:             "results": result.get("results", []),
 120:             "disambiguation": {
 121:                 **(chosen or {}),
 122:                 "reason": (result.get("chosen") or {}).get("reason"),
 123:                 "retrieval_confidence": (result.get("chosen") or {}).get("retrieval_confidence"),
 124:                 "llm_confidence": (result.get("chosen") or {}).get("llm_confidence"),
 125:             },
 126:             "alternatives": result.get("alternatives", []),
 127:         }
 128:     else:
 129:         out = {
 130:             **(chosen or {}),
 131:             "reason": (result.get("chosen") or {}).get("reason"),
 132:             "retrieval_confidence": (result.get("chosen") or {}).get("retrieval_confidence"),
 133:             "llm_confidence": (result.get("chosen") or {}).get("llm_confidence"),
 134:         }
 135:         if args.num_choices and args.num_choices > 0:
 136:             out = {
 137:                 **out,
 138:                 "alternatives": result.get("alternatives", [])
 139:             }
 140:     print(json.dumps(out, indent=2))

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/config.py
Size: 106 lines
================================================================================
   1: import os
   2: import json
   3: from pydantic import BaseModel, Field
   4: from typing import Optional, List, Dict
   5: 
   6: # Load environment variables from .env file
   7: try:
   8:     from dotenv import load_dotenv
   9:     load_dotenv()
  10: except ImportError:
  11:     # Fallback if python-dotenv is not available
  12:     pass
  13: 
  14: def _parse_ontologies(env_var: str) -> Optional[List[str]]:
  15:     """Parse comma-separated ontology list from environment variable"""
  16:     val = os.getenv(env_var)
  17:     if not val:
  18:         return None
  19:     return [item.strip() for item in val.split(',') if item.strip()]
  20: 
  21: class BondSettings(BaseModel):
  22:     # Core paths (new schema only)
  23:     assets_path: str = Field(default=os.getenv("BOND_ASSETS_PATH", "assets"))
  24:     # Always derive sqlite path from assets path; new schema filename only
  25:     sqlite_path: str = Field(default="assets/ontologies.sqlite")
  26: 
  27:     # Embeddings
  28:     # Accept new env var BOND_EMBED_MODEL; fallback to legacy BOND_EMBED_SPEC for BC
  29:     embed_model: str = Field(default=(os.getenv("BOND_EMBED_MODEL") or os.getenv("BOND_EMBED_SPEC") or "st:all-MiniLM-L6-v2"))
  30:     litellm_api_base: str = Field(default=os.getenv("LITELLM_API_BASE", ""))
  31: 
  32:     # Separate LLMs for expansion and disambiguation (required)
  33:     expansion_llm_model: str = Field(default=(os.getenv("BOND_EXPANSION_LLM") or os.getenv("BOND_EXPANSION_LLM_MODEL") or ""))
  34:     disambiguation_llm_model: str = Field(default=(os.getenv("BOND_DISAMBIGUATION_LLM") or os.getenv("BOND_DISAMBIGUATION_LLM_MODEL") or ""))
  35: 
  36:     # Retrieval parameters
  37:     topk_exact: int = Field(default=int(os.getenv("BOND_TOPK_EXACT", 5)))
  38:     topk_bm25: int = Field(default=int(os.getenv("BOND_TOPK_BM25", 20)))
  39:     topk_dense: int = Field(default=int(os.getenv("BOND_TOPK_DENSE", 50)))
  40:     # topk_final: Drives both the fusion list shown in trace and the set of
  41:     # candidates provided to the disambiguation LLM.
  42:     topk_final: int = Field(default=int(os.getenv("BOND_TOPK_FINAL", 20)))
  43:     rrf_k: float = Field(default=float(os.getenv("BOND_RRF_K", 60.0)))
  44: 
  45:     # RRF source weighting (JSON string preferred; falls back to per-weight envs for BC)
  46:     rrf_weights: Dict[str, float] = Field(
  47:         default_factory=lambda: (
  48:             (lambda s: (json.loads(s) if s else {
  49:                 "exact": float(os.getenv("BOND_RRF_EXACT_WEIGHT", 1.0)),
  50:                 "bm25": float(os.getenv("BOND_RRF_BM25_WEIGHT", 0.8)),
  51:                 "dense": float(os.getenv("BOND_RRF_DENSE_WEIGHT", 0.6)),
  52:                 # Context-augmented channels
  53:                 "bm25_ctx": float(os.getenv("BOND_RRF_BM25_CTX_WEIGHT", 0.72)),  # ~bm25*0.9 by default
  54:                 # New: intent-based dense channel (replaces dense_ctx)
  55:                 "dense_full": float(os.getenv("BOND_RRF_DENSE_FULL_WEIGHT", os.getenv("BOND_RRF_DENSE_CTX_WEIGHT", 0.6))),
  56:             })) (os.getenv("BOND_RRF_WEIGHTS"))
  57:         )
  58:     )
  59: 
  60:     rescore_multiplier: int = Field(default=int(os.getenv("BOND_RESCORE_MULTIPLIER", 20)))
  61:     enable_expansion: bool = Field(default=bool(int(os.getenv("BOND_EXPANSION", 1))))
  62:     n_expansions: int = Field(default=int(os.getenv("BOND_N_EXPANSIONS", 3)))
  63:     log_level: str = Field(default=os.getenv("BOND_LOG_LEVEL", "INFO"))
  64:     use_gpu: bool = Field(default=bool(int(os.getenv("BOND_USE_GPU", 1))))
  65:     restrict_to_ontologies: Optional[List[str]] = Field(
  66:         default_factory=lambda: _parse_ontologies("BOND_RESTRICT_TO_ONTOLOGIES"),
  67:         description="Default list of ontology sources to restrict search to."
  68:     )
  69:     # New schema tables only
  70:     table_terms: str = "ontology_terms"
  71:     table_terms_fts: str = "ontology_terms_fts"
  72: 
  73:     # Re-ranking boosts
  74:     exact_match_boost: float = Field(default=float(os.getenv("BOND_EXACT_MATCH_BOOST", 10.0)))
  75:     ontology_prior_boost: float = Field(default=float(os.getenv("BOND_ONTOLOGY_PRIOR_BOOST", 0.5)))
  76:     context_overlap_boost: float = Field(default=float(os.getenv("BOND_CONTEXT_OVERLAP_BOOST", 0.2)))
  77: 
  78:     # Graph expansion (auto by default)
  79:     graph_mode: str = Field(default=os.getenv("BOND_GRAPH_MODE", "auto"))  # one of: off|auto|on
  80:     graph_auto_fields: List[str] = Field(
  81:         default_factory=lambda: [s.strip() for s in (os.getenv("BOND_GRAPH_AUTO_FIELDS", "tissue,development_stage,cell_type").split(",")) if s.strip()]
  82:     )
  83:     graph_auto_depth: int = Field(default=int(os.getenv("BOND_GRAPH_DEPTH_AUTO", 1)))
  84:     graph_weight: float = Field(default=float(os.getenv("BOND_GRAPH_WEIGHT", 0.7)))
  85:     graph_top1_min: float = Field(default=float(os.getenv("BOND_GRAPH_TOP1_MIN", 0.35)))
  86:     graph_top3_mean_min: float = Field(default=float(os.getenv("BOND_GRAPH_TOP3_MEAN_MIN", 0.25)))
  87: 
  88:     # Post-fusion lexical boost over term_doc using query+expansions+context tokens
  89:     term_doc_overlap_boost: float = Field(default=float(os.getenv("BOND_TERM_DOC_OVERLAP_BOOST", 0.15)))
  90: 
  91:     # Retrieval-only mode (skip LLM expansion/disambiguation)
  92:     retrieval_only: bool = Field(default=bool(int(os.getenv("BOND_RETRIEVAL_ONLY", 0))))
  93: 
  94:     # LLM/Embedding provider resilience knobs
  95:     llm_timeout_seconds: int = Field(default=int(os.getenv("BOND_LLM_TIMEOUT", 30)))
  96:     llm_max_retries: int = Field(default=int(os.getenv("BOND_LLM_RETRIES", 3)))
  97:     embed_timeout_seconds: int = Field(default=int(os.getenv("BOND_EMBED_TIMEOUT", 30)))
  98:     embed_max_retries: int = Field(default=int(os.getenv("BOND_EMBED_RETRIES", 3)))
  99: 
 100:     # Semantic intent rerank using FAISS rescore vectors
 101:     enable_semantic_intent_rerank: bool = Field(default=bool(int(os.getenv("BOND_SEMANTIC_INTENT_RERANK", 1))))
 102:     semantic_intent_weight: float = Field(default=float(os.getenv("BOND_SEMANTIC_INTENT_WEIGHT", 0.5)))
 103: 
 104:     def model_post_init(self, __context: Dict) -> None:  # type: ignore[override]
 105:         # Derive sqlite path from assets_path always (new schema filename)
 106:         self.sqlite_path = os.path.join(self.assets_path, "ontologies.sqlite")

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/field_guidance.py
Size: 95 lines
================================================================================
   1: # bond/field_guidance.py
   2: from typing import Dict
   3: 
   4: FIELD_GUIDANCE: Dict[str, Dict[str, str]] = {
   5:     "cell_type": {
   6:         "semantic_constraints": "MUST be a cellular entity (from Cell Ontology or species-specific anatomy). PROHIBITED: genes, proteins, biological processes (GO terms), diseases, or anatomical structures.",
   7:         "expansion_focus": "Lineage-preserving variants, activation states, common synonyms, and marker combinations (e.g., CD4-positive).",
   8:         "context_priority": "Lineage, activation state, surface markers, anatomical subregion relevant to tissue context.",
   9:         "avoid": "Gene symbols alone, GO processes, diseases, assay/platform names.",
  10:         "disambiguation_rules": (
  11:             "1. **SEMANTIC TYPE CHECK:** First, ensure the candidate is a cell type. Immediately REJECT any candidate that is a biological process (e.g., GO terms), a gene, or a protein. "
  12:             "2. **CONTRADICTION CHECK:** Scrutinize for direct contradictions. If the query specifies 'M1', any 'M2 macrophage' candidate is INVALID and MUST be rejected. If the query specifies 'CD4-positive', a 'CD8-positive' candidate is INVALID. This rule overrides retrieval score. "
  13:             "3. **POSITIVE SIGNAL MATCH:** After eliminating contradictions, give highest preference to candidates that positively match explicit signals (markers like 'CD25+', states like 'activated', provenance like 'monocyte-derived'). "
  14:             "4. **LINEAGE CONSISTENCY:** The candidate must belong to the correct biological lineage implied by the query. "
  15:             "5. **SPECIFICITY & TIE-BREAKING:** Match the query's level of detail; use retrieval score only to break ties between otherwise valid candidates."
  16:         )
  17:     },
  18:     "tissue": {
  19:         "semantic_constraints": "MUST be an anatomical entity (organ, tissue, or substructure from UBERON or species-specific anatomy). PROHIBITED: cell types, diseases, assays.",
  20:         "expansion_focus": "Synonyms and immediate parent/child anatomical terms (e.g., 'lung' -> 'pulmonary tissue').",
  21:         "context_priority": "Organ/system, subregion (e.g., lobe, cortex), laterality if applicable.",
  22:         "avoid": "Cell types, biological processes, disease names, assay terms.",
  23:         "disambiguation_rules": (
  24:             "1. **SEMANTIC TYPE CHECK:** Candidate MUST be an anatomical structure. REJECT cell types or biological processes. "
  25:             "2. **CONTEXTUAL ALIGNMENT:** Use provided context to resolve ambiguity (e.g., for 'cortex' with tissue 'adrenal gland', choose 'adrenal cortex'). REJECT anatomically incompatible locations. "
  26:             "3. **HIERARCHICAL ACCURACY:** Choose the correct anatomical level. Prefer the direct organ/tissue match over a minute substructure unless the query is highly specific."
  27:         )
  28:     },
  29:     "disease": {
  30:         "semantic_constraints": "MUST be a pathological condition from MONDO. The term 'normal' or 'healthy' MUST map to PATO:0000461.",
  31:         "expansion_focus": "Common clinical synonyms, disease subtypes, and related pathological processes.",
  32:         "context_priority": "Anatomical site, etiology, subtype, onset/severity modifiers.",
  33:         "avoid": "Physiological traits, experimental conditions, assays, non-pathological phenotypes unless explicitly 'healthy'.",
  34:         "disambiguation_rules": (
  35:             "1. **SEMANTIC TYPE CHECK:** Candidate MUST be a disease from MONDO or PATO:0000461 for 'healthy'. "
  36:             "2. **KEYWORD ALIGNMENT:** Candidate label or synonyms should contain the core disease concept from the query. "
  37:             "3. **SPECIFICITY MATCH:** If a subtype is specified (e.g., 'adenocarcinoma'), REJECT the generic parent ('carcinoma') when the specific subtype is available."
  38:         )
  39:     },
  40:     "development_stage": {
  41:         "semantic_constraints": "MUST be a developmental stage from the correct organism-specific ontology (e.g., HsapDv, MmusDv).",
  42:         "expansion_focus": "Standard stage names, synonyms, and common temporal descriptions (e.g., 'embryonic day 14.5' -> 'E14.5').",
  43:         "context_priority": "Species-appropriate stage terms, exact timepoint format (e.g., E14.5), prenatal/postnatal.",
  44:         "avoid": "Anatomical structures, cell types, disease modifiers.",
  45:         "disambiguation_rules": (
  46:             "1. **ONTOLOGY SOURCE:** Candidate MUST come from the correct species-specific developmental ontology. "
  47:             "2. **TEMPORAL ACCURACY:** Choose the term that most accurately reflects the age or stage mentioned in the query. Reject anatomical terms."
  48:         )
  49:     },
  50:     "sex": {
  51:         "semantic_constraints": "MUST be a biological sex from PATO.",
  52:         "expansion_focus": "Canonical terms like 'male', 'female', 'hermaphrodite'.",
  53:         "context_priority": "Exact sex terms only; no fuzzy synonyms.",
  54:         "avoid": "Gender identity terms, karyotype-only phrases unless explicit, unrelated traits.",
  55:         "disambiguation_rules": (
  56:             "1. **KEYWORD FIRST:** Choose the candidate that is an exact or synonymous match to the query word. "
  57:             "2. **REJECT SEMANTIC DRIFT:** Be highly skeptical of candidates that do not share exact keywords, regardless of vector similarity. The vocabulary is too small for fuzzy matching."
  58:         )
  59:     },
  60:     "self_reported_ethnicity": {
  61:         "semantic_constraints": "MUST be an ancestry or population category from HANCESTRO.",
  62:         "expansion_focus": "Standard biomedical ancestry groups and geographical synonyms.",
  63:         "context_priority": "Continental or major population groups unless a specific subpopulation is stated.",
  64:         "avoid": "Nationality, language, religion; overly granular subpopulations without explicit mention.",
  65:         "disambiguation_rules": (
  66:             "1. **KEYWORD FIRST:** Prefer candidates that are an exact or synonymous match to the query. "
  67:             "2. **HIERARCHY:** Choose the appropriate population resolution. Prefer broader continental groups unless a specific sub-population is explicitly mentioned."
  68:         )
  69:     },
  70:     "assay": {
  71:         "semantic_constraints": "MUST be an experimental method or assay from EFO.",
  72:         "expansion_focus": "Platform names, technology synonyms, and full experimental names.",
  73:         "context_priority": "Platform/chemistry, version, library prep specifics.",
  74:         "avoid": "Biological entities, disease names, anatomical structures.",
  75:         "disambiguation_rules": (
  76:             "1. **KEYWORD FIRST:** The candidate label or synonym MUST contain the core technology or platform name from the query (e.g., '10x', 'SMART-seq'). "
  77:             "2. **REJECT BIOLOGICAL TERMS:** Immediately reject any candidate that is a biological entity instead of a technical method."
  78:         )
  79:     },
  80:     "organism": {
  81:         "semantic_constraints": "MUST be a species or taxon from NCBITaxon.",
  82:         "expansion_focus": "Canonical scientific names and common names (e.g., 'Homo sapiens' -> 'human').",
  83:         "context_priority": "Species-level naming; strain only if explicitly mentioned.",
  84:         "avoid": "Cell lines, tissues, diseases, processes.",
  85:         "disambiguation_rules": (
  86:             "1. **KEYWORD FIRST:** Choose the candidate that is an exact or synonymous match to the query name. "
  87:             "2. **TAXONOMIC LEVEL:** Prefer the species level over subspecies or strains unless a specific strain is explicitly mentioned in the query."
  88:         )
  89:     },
  90: }
  91: 
  92: def get_field_guidance(field_name: str | None) -> Dict[str, str]:
  93:     if not field_name:
  94:         return {}
  95:     return FIELD_GUIDANCE.get(field_name.lower(), {})

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/fusion.py
Size: 29 lines
================================================================================
   1: from typing import Dict, List, Tuple
   2: from collections import defaultdict
   3: 
   4: def rrf_fuse(rankings: Dict[str, List[str]], k: float = 60.0, weights: Dict[str, float] | None = None) -> List[Tuple[str, float]]:
   5:     """
   6:     Reciprocal Rank Fusion with optional source weighting.
   7: 
   8:     Args:
   9:         rankings: Dict mapping source names to lists of ranked IDs
  10:         k: RRF parameter (default 60.0)
  11:         weights: Optional dict mapping source names to weights (default: all sources weighted equally)
  12: 
  13:     Returns:
  14:         List of (id, score) tuples sorted by score descending
  15:     """
  16:     scores = defaultdict(float)
  17: 
  18:     # Default weights if none provided
  19:     if weights is None:
  20:         weights = {src: 1.0 for src in rankings.keys()}
  21: 
  22:     for src, ids in rankings.items():
  23:         weight = weights.get(src, 1.0)  # Default weight 1.0 for unknown sources
  24:         for rank, id_ in enumerate(ids, start=1):
  25:             scores[id_] += weight / (k + rank)
  26: 
  27:     fused = list(scores.items())
  28:     fused.sort(key=lambda x: x[1], reverse=True)
  29:     return fused

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/fusion_weights.py
Size: 18 lines
================================================================================
   1: from typing import Dict
   2: 
   3: 
   4: def field_aware_weights(field_name: str) -> Dict[str, float]:
   5:     """Return field-specific RRF weights.
   6: 
   7:     Adjusts source importance per domain to steer fusion sensibly.
   8:     """
   9:     field_lower = (field_name or "").lower()
  10: 
  11:     if field_lower in {"assay", "assay_type", "protocol"}:
  12:         return {"exact": 1.5, "bm25": 0.9, "dense": 0.4}
  13:     if field_lower in {"cell_type", "celltype", "cell"}:
  14:         return {"exact": 1.0, "bm25": 0.7, "dense": 1.2}
  15:     if field_lower in {"disease", "condition", "pathology"}:
  16:         return {"exact": 1.2, "bm25": 0.8, "dense": 0.8}
  17:     return {"exact": 1.0, "bm25": 0.8, "dense": 0.6}
  18: 

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/graph_utils.py
Size: 55 lines
================================================================================
   1: from typing import Dict, List
   2: import sqlite3
   3: 
   4: 
   5: def compute_graph_neighbors(
   6:     conn: sqlite3.Connection,
   7:     table_terms: str,
   8:     seed_ids: List[str],
   9:     depth: int,
  10: ) -> Dict[str, int]:
  11:     """Return neighbor node -> distance for graph expansion within ontology terms.
  12: 
  13:     Ensures neighbors exist in the terms table to avoid unresolvable IDs.
  14:     """
  15:     if depth <= 0 or not seed_ids:
  16:         return {}
  17:     cur = conn.cursor()
  18:     neighbors: Dict[str, int] = {}
  19:     seen = set(seed_ids)
  20:     frontier = set(seed_ids)
  21: 
  22:     # Check edges table exists
  23:     try:
  24:         has_edges = bool(cur.execute("SELECT 1 FROM sqlite_master WHERE type='table' AND name='ontology_edges'").fetchone())
  25:     except Exception:
  26:         has_edges = False
  27:     if not has_edges:
  28:         return {}
  29: 
  30:     for d in range(1, depth + 1):
  31:         if not frontier:
  32:             break
  33:         qmarks = ",".join("?" for _ in frontier)
  34:         try:
  35:             rows_p = cur.execute(
  36:                 f"SELECT DISTINCT e.target_curie FROM ontology_edges e JOIN {table_terms} t ON t.curie = e.target_curie WHERE e.source_curie IN ({qmarks})",
  37:                 list(frontier),
  38:             ).fetchall()
  39:             rows_c = cur.execute(
  40:                 f"SELECT DISTINCT e.source_curie FROM ontology_edges e JOIN {table_terms} t ON t.curie = e.source_curie WHERE e.target_curie IN ({qmarks})",
  41:                 list(frontier),
  42:             ).fetchall()
  43:         except Exception:
  44:             break
  45:         new_nodes = [r[0] for r in rows_p] + [r[0] for r in rows_c]
  46:         next_frontier = []
  47:         for nid in new_nodes:
  48:             if nid and nid not in seen:
  49:                 seen.add(nid)
  50:                 neighbors[nid] = d
  51:                 next_frontier.append(nid)
  52:         frontier = set(next_frontier)
  53: 
  54:     return neighbors
  55: 

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/logger.py
Size: 37 lines
================================================================================
   1: # bond/logger.py
   2: import logging
   3: import sys
   4: import os
   5: 
   6: # Load environment variables from .env file
   7: try:
   8:     from dotenv import load_dotenv
   9:     load_dotenv()
  10: except ImportError:
  11:     # Fallback if python-dotenv is not available
  12:     pass
  13: 
  14: def setup_logger():
  15:     """Sets up a standardized logger for the BOND project."""
  16:     logger = logging.getLogger("bond")
  17: 
  18:     # Set log level from environment variable
  19:     log_level = os.getenv("BOND_LOG_LEVEL", "WARNING").upper()
  20:     logger.setLevel(getattr(logging, log_level, logging.INFO))
  21: 
  22:     # Avoid adding duplicate handlers
  23:     if logger.hasHandlers():
  24:         logger.handlers.clear()
  25: 
  26:     # Console handler
  27:     handler = logging.StreamHandler(sys.stderr)
  28:     formatter = logging.Formatter(
  29:         '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
  30:         datefmt='%Y-%m-%d %H:%M:%S'
  31:     )
  32:     handler.setFormatter(formatter)
  33:     logger.addHandler(handler)
  34: 
  35:     return logger
  36: 
  37: logger = setup_logger()

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/models.py
Size: 164 lines
================================================================================
   1: """
   2: Pydantic models for BOND API requests, responses, and internal data structures.
   3: These models provide automatic validation, strong typing, and self-documenting schemas.
   4: """
   5: 
   6: from pydantic import BaseModel, Field, ConfigDict
   7: from typing import Optional, List, Dict, Any
   8: from datetime import datetime
   9: 
  10: # =============================================================================
  11: # REQUEST MODELS
  12: # =============================================================================
  13: 
  14: class QueryItem(BaseModel):
  15:     """Individual query request item"""
  16:     query: str = Field(..., description="The text query to search for")
  17:     field_name: str = Field(
  18:         ...,
  19:         description="Schema field being standardized (e.g., cell_type, tissue)",
  20:     )
  21:     organism: str = Field(..., description="Organism (canonical name)")
  22:     tissue: str = Field(..., description="Tissue/organ context (e.g., lung, brain)")
  23:     # Optional knobs used by /query endpoint
  24:     n_expansions: Optional[int] = Field(None, description="Override default number of expansions")
  25:     topk_final: Optional[int] = Field(None, description="Override default number of final results")
  26:     num_choices: Optional[int] = Field(None, description="Number of top alternatives to include (in addition to chosen)")
  27:     topk_exact: Optional[int] = Field(None, description="Override top-k for exact match retrieval")
  28:     topk_bm25: Optional[int] = Field(None, description="Override top-k for BM25 retrieval")
  29:     topk_dense: Optional[int] = Field(None, description="Override top-k for vector retrieval")
  30:     rrf_k: Optional[float] = Field(None, description="Override RRF k parameter")
  31:     exact_only: Optional[bool] = Field(None, description="If true, use exact channel only")
  32:     graph_depth: Optional[int] = Field(None, description="Graph expansion depth (0 disables)")
  33:     rerank_after_graph: Optional[bool] = Field(None, description="Run second RRF after graph expansion")
  34:     return_trace: Optional[bool] = Field(None, description="Override default trace setting")
  35: 
  36: 
  37: # =============================================================================
  38: # RESPONSE MODELS
  39: # =============================================================================
  40: 
  41: class QueryResultItem(BaseModel):
  42:     """Individual result item from a query"""
  43:     id: str = Field(..., description="Unique identifier for the ontology term")
  44:     label: str = Field(..., description="Human-readable label for the term")
  45:     source: str = Field(..., description="Source ontology (e.g., 'cl', 'mondo')")
  46:     iri: Optional[str] = Field(None, description="Full IRI for the ontology term (e.g., PURL)")
  47:     definition: Optional[str] = Field(None, description="Canonical definition text")
  48:     synonyms_exact: Optional[List[str]] = Field(default=None, description="Exact synonyms")
  49:     synonyms_related: Optional[List[str]] = Field(default=None, description="Related synonyms")
  50:     synonyms_broad: Optional[List[str]] = Field(default=None, description="Broad synonyms")
  51:     fusion_score: float = Field(..., description="Reciprocal Rank Fusion score")
  52:     retrieval_confidence: Optional[float] = Field(None, description="Normalized retrieval confidence [0,1]")
  53:     reason: Optional[str] = Field(None, description="LLM's reason for choosing this term")
  54:     llm_confidence: Optional[float] = Field(None, description="LLM's confidence in its choice [0,1]")
  55: 
  56: class QueryResponse(BaseModel):
  57:     """Deprecated in favor of custom JSON contract returned by server."""
  58:     results: List[QueryResultItem] = Field(default_factory=list)
  59:     chosen: Optional[QueryResultItem] = None
  60:     alternatives: Optional[List[QueryResultItem]] = None
  61:     trace: Optional[Dict[str, Any]] = None
  62:     error: Optional[str] = None
  63: 
  64: class BatchResponse(BaseModel):
  65:     """Deprecated in favor of custom JSON contract returned by server."""
  66:     results: List[QueryResponse] = Field(default_factory=list)
  67:     summary: Dict[str, Any] = Field(default_factory=dict)
  68: 
  69: # =============================================================================
  70: # CONFIGURATION MODELS
  71: # =============================================================================
  72: 
  73: class BondConfig(BaseModel):
  74:     """Deprecated config model; server returns raw cfg now."""
  75:     model_config = ConfigDict(extra="ignore")
  76: 
  77: class OntologyInfo(BaseModel):
  78:     """Information about available ontologies"""
  79:     sources: List[str] = Field(..., description="List of available ontology sources")
  80:     total_terms: int = Field(..., description="Total number of terms across all ontologies")
  81:     last_updated: Optional[datetime] = Field(None, description="When the index was last built")
  82: 
  83: # =============================================================================
  84: # INTERNAL DATA MODELS
  85: # =============================================================================
  86: 
  87: class EmbeddingSignature(BaseModel):
  88:     """Model signature for embedding validation"""
  89:     model_id: str = Field(..., description="Identifier for the embedding model")
  90:     dimension: int = Field(..., description="Embedding vector dimension")
  91:     anchor_text: str = Field(..., description="Reference text used for validation")
  92:     anchor_vector: List[float] = Field(..., description="Reference embedding vector")
  93: 
  94: class IndexMetadata(BaseModel):
  95:     """Metadata for FAISS index profiles"""
  96:     profile: str = Field(..., description="Index profile name")
  97:     method: str = Field(..., description="Indexing method used")
  98:     embedding_model: str = Field(..., description="Source embedding model")
  99:     normalize: bool = Field(..., description="Whether embeddings are normalized")
 100:     dimension: int = Field(..., description="Embedding dimension")
 101:     notes: str = Field(..., description="Additional implementation notes")
 102:     created_at: Optional[str] = Field(None, description="When the index was created (ISO format)")
 103: 
 104: # =============================================================================
 105: # LLM STRUCTURED RESPONSES
 106: # =============================================================================
 107: 
 108: class ExpansionResponse(BaseModel):
 109:     """Expected structure from expansion LLM."""
 110:     expansions: List[str] = Field(default_factory=list)
 111:     context_terms: List[str] = Field(default_factory=list)
 112: 
 113: class DisambiguationResponse(BaseModel):
 114:     """Expected structure from disambiguation LLM."""
 115:     chosen_id: str | None  # Allow None for abstain capability
 116:     reason: Optional[str] = None
 117:     llm_confidence: Optional[float] = None
 118:     alternatives: Optional[List[str]] = None
 119: 
 120: class TraceInfo(BaseModel):
 121:     """Detailed trace information for debugging"""
 122:     query: str = Field(..., description="Original query text")
 123:     profile: str = Field(..., description="Index profile used")
 124:     expansions: List[str] = Field(default_factory=list, description="Generated query expansions")
 125:     candidates: Dict[str, List[str]] = Field(..., description="Candidate IDs from each retrieval method")
 126:     fusion: List[tuple] = Field(..., description="Fusion results with scores")
 127:     disambiguation: Dict[str, Any] = Field(..., description="LLM disambiguation details")
 128:     ontology_filter: Optional[List[str]] = Field(None, description="Applied ontology restrictions")
 129: 
 130: # =============================================================================
 131: # HEALTH AND STATUS MODELS
 132: # =============================================================================
 133: 
 134: class HealthResponse(BaseModel):
 135:     """Health check response"""
 136:     status: str = Field(..., description="Service health status")
 137:     timestamp: datetime = Field(..., description="Current server timestamp")
 138:     service: str = Field(..., description="Service name")
 139:     version: str = Field(..., description="Service version")
 140:     uptime: Optional[float] = Field(None, description="Service uptime in seconds")
 141: 
 142: class ErrorResponse(BaseModel):
 143:     """Standard error response"""
 144:     error: str = Field(..., description="Error message")
 145:     detail: Optional[str] = Field(None, description="Additional error details")
 146:     timestamp: datetime = Field(default_factory=datetime.now, description="When the error occurred")
 147: 
 148: # =============================================================================
 149: # UTILITY MODELS
 150: # =============================================================================
 151: 
 152: class SearchResult(BaseModel):
 153:     """Generic search result structure"""
 154:     id: str
 155:     label: str
 156:     score: float
 157:     source: str
 158:     metadata: Optional[Dict[str, Any]] = None
 159: 
 160: class FusionResult(BaseModel):
 161:     """Result from reciprocal rank fusion"""
 162:     id: str
 163:     score: float
 164:     rank: int

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/pipeline.py
Size: 1012 lines
================================================================================
   1: import os
   2: import sqlite3
   3: import threading
   4: import numpy as np
   5: from typing import Optional, Dict, Any, List
   6: from concurrent.futures import ThreadPoolExecutor
   7: from datetime import datetime
   8: import time
   9: from .config import BondSettings
  10: from .providers import resolve_embeddings, ChatLLM
  11: from .retrieval.bm25_sqlite import search_exact, search_bm25
  12: from .retrieval.faiss_store import FaissStore
  13: from .fusion import rrf_fuse
  14: from .prompts import QUERY_EXPANSION_PROMPT, DISAMBIGUATION_PROMPT, CONTEXT_TERMS_PROMPT
  15: from .models import ExpansionResponse, DisambiguationResponse
  16: from .validate_signature import validate_embedding_signature
  17: from .logger import logger
  18: from .runtime_env import configure_runtime
  19: from .schema_policies import allowed_ontologies_for
  20: from .field_guidance import get_field_guidance
  21: from .rules import should_abstain, context_violation, species_violation, normalize_organism, normalize_marker_suffixes, normalize_field_name
  22: from .abbrev import AbbreviationExpander
  23: from .fusion_weights import field_aware_weights
  24: from .graph_utils import compute_graph_neighbors
  25: from .rerank import apply_soft_boosts
  26: configure_runtime()
  27: 
  28: # Helper to parse LLM JSON into a Pydantic model
  29: import json, re
  30: from typing import Type, TypeVar
  31: from pydantic import BaseModel
  32: _T = TypeVar("_T", bound=BaseModel)
  33: 
  34: def _extract_json_str(text: str):
  35:     m = re.search(r"```(?:json)?\s*\n?(.*?)\n?```", text, re.DOTALL | re.IGNORECASE)
  36:     if m:
  37:         return m.group(1).strip()
  38:     s = text.find("{")
  39:     e = text.rfind("}")
  40:     if s != -1 and e != -1 and e > s:
  41:         return text[s:e+1]
  42:     return None
  43: 
  44: def parse_llm_json(text: str, model: Type[_T]) -> _T | None:
  45:     js = _extract_json_str(text)
  46:     if not js:
  47:         return None
  48:     try:
  49:         data = json.loads(js)
  50:         return model.model_validate(data)
  51:     except Exception:
  52:         return None
  53: 
  54: 
  55: # use the shared configured logger from bond.logger
  56: 
  57: def _normalize(s: str) -> str:
  58:     return " ".join(s.lower().split())
  59: 
  60: def _uniq(seq: List) -> List:
  61:     seen = set()
  62:     return [x for x in seq if not (x in seen or seen.add(x))]
  63: 
  64: 
  65: class BondMatcher:
  66:     def __init__(self, settings: Optional[BondSettings] = None):
  67:         self.cfg = settings or BondSettings()
  68:         logger.info("Initializing BOND")
  69: 
  70:         # Create per-thread SQLite connection using immutable, read-only URI
  71:         self.db_path = self.cfg.sqlite_path or os.path.join(self.cfg.assets_path, "ontologies.sqlite")
  72:         if not os.path.exists(self.db_path):
  73:             raise FileNotFoundError(f"Database not found: {self.db_path}")
  74: 
  75:         logger.info("BOND matcher initialized (connections created per-thread)")
  76: 
  77:         # Thread-safe connection method
  78:         self._connection_pool = {}
  79:         self._connection_lock = threading.Lock()
  80: 
  81:         # Thread-safe connection with proper URI and pragmas
  82:         def get_connection():
  83:             thread_id = threading.get_ident()
  84:             with self._connection_lock:
  85:                 if thread_id not in self._connection_pool:
  86:                     conn = sqlite3.connect(
  87:                         f"file:{self.db_path}?mode=ro&immutable=1",
  88:                         uri=True,
  89:                         check_same_thread=False
  90:                     )
  91:                     conn.row_factory = sqlite3.Row
  92:                     # Set performance pragmas
  93:                     conn.execute("PRAGMA cache_size=10000")
  94:                     conn.execute("PRAGMA journal_mode=OFF")
  95:                     conn.execute("PRAGMA query_only=ON")
  96:                     self._connection_pool[thread_id] = conn
  97:                 return self._connection_pool[thread_id]
  98: 
  99:         self.get_connection = get_connection
 100: 
 101:         # Basic metrics
 102:         self._start_time = datetime.now()
 103:         self._request_count = 0
 104: 
 105:         # Single FAISS store
 106:         self.faiss = FaissStore(self.cfg.assets_path, self.cfg.rescore_multiplier)
 107:         # Embedding model auto-resolved (supports litellm style strings)
 108:         self.embed_fn = resolve_embeddings(self.cfg.embed_model)
 109:         # Validate embedding signature
 110:         validate_embedding_signature(self.faiss.signature_path, self.embed_fn)
 111:         logger.info("Embedding signature validated successfully.")
 112: 
 113:         # Initialize separate LLMs unless in retrieval-only mode
 114:         self.expansion_llm = None
 115:         self.disamb_llm = None
 116:         if not self.cfg.retrieval_only:
 117:             if not self.cfg.expansion_llm_model or not self.cfg.disambiguation_llm_model:
 118:                 raise RuntimeError("BOND_EXPANSION_LLM and BOND_DISAMBIGUATION_LLM must be set (or set BOND_RETRIEVAL_ONLY=1)")
 119:             self.expansion_llm = ChatLLM(self.cfg.expansion_llm_model)
 120:             self.disamb_llm = ChatLLM(self.cfg.disambiguation_llm_model)
 121:             logger.info(f"Expansion LLM: {self.cfg.expansion_llm_model}")
 122:             logger.info(f"Disambiguation LLM: {self.cfg.disambiguation_llm_model}")
 123: 
 124:         self.executor = ThreadPoolExecutor(max_workers=3)
 125:         logger.info("ThreadPoolExecutor initialized for parallel retrieval")
 126: 
 127:         # Abbreviation expander (field-scoped)
 128:         from .abbrev import AbbreviationExpander
 129:         self.abbrev = AbbreviationExpander(self.cfg.assets_path)
 130: 
 131:     def _build_intent_text(
 132:         self,
 133:         query: str,
 134:         field_name: str | None,
 135:         organism: str | None,
 136:         tissue: str | None,
 137:         queries_with_expansions: list[str] | None,
 138:         context_terms: list[str] | None,
 139:     ) -> str:
 140:         """Construct a deterministic intent string for dense_full embedding.
 141: 
 142:         This captures base query, field context, organism/tissue hints, expansions,
 143:         and derived context terms — without using any LLM.
 144:         """
 145:         parts: list[str] = []
 146:         if field_name:
 147:             parts.append(f"field={field_name}")
 148:         if organism:
 149:             parts.append(f"organism={organism}")
 150:         if tissue:
 151:             parts.append(f"tissue={tissue}")
 152:         parts.append(f"query={query}")
 153:         if queries_with_expansions and len(queries_with_expansions) > 1:
 154:             alts = [q for q in queries_with_expansions[1:5] if q and q != query]
 155:             if alts:
 156:                 parts.append("alts=" + " | ".join(alts))
 157:         if context_terms:
 158:             parts.append("ctx=" + ", ".join(context_terms[:5]))
 159:         return " ; ".join(parts)
 160: 
 161:     def _expand_abbreviations(self, text: str, field_name: str | None) -> str:
 162:         try:
 163:             return self.abbrev.expand(text, field_name)
 164:         except Exception:
 165:             return text
 166: 
 167:     def _derive_context_terms(
 168:         self,
 169:         base_query: str,
 170:         field_name: str | None,
 171:         tissue: str | None,
 172:         organism: str | None,
 173:     ) -> List[str]:
 174:         """Derive up to 5 high-signal context terms using multiple methods.
 175:         Methods:
 176:           - Field-default domain vocabulary (lightweight priors)
 177:           - BM25 over tissue ontologies to extract anatomical tokens (if tissue provided)
 178:           - LLM-based suggestion via CONTEXT_TERMS_PROMPT
 179:         """
 180:         logger.info("Deriving context terms (multi-method)...")
 181:         field_lower = (field_name or "").lower()
 182:         out: List[str] = []
 183: 
 184:         # 1) Field-default priors
 185:         FIELD_PRIORS: Dict[str, List[str]] = {
 186:             "cell_type": ["lineage", "marker", "population"],
 187:             "tissue": ["region", "layer", "subdivision"],
 188:             "disease": ["pathology", "syndrome", "disorder"],
 189:             "development_stage": ["embryonic", "fetal", "adult"],
 190:             "sex": ["male", "female"],
 191:             "self_reported_ethnicity": ["ancestry", "population", "continental"],
 192:             "assay": ["protocol", "platform", "technology"],
 193:             "organism": ["species", "strain"],
 194:         }
 195:         priors = FIELD_PRIORS.get(field_lower, [])
 196: 
 197:         # 2) BM25 anatomical tokens from tissue (restricted to tissue ontologies)
 198:         bm25_tokens: List[str] = []
 199:         if tissue:
 200:             try:
 201:                 tissue_sources = allowed_ontologies_for("tissue", organism)
 202:                 if tissue_sources:
 203:                     # Query BM25 for tissue string
 204:                     rows: List[Dict[str, Any]] = search_bm25(
 205:                         self.get_connection(), self.cfg.table_terms, self.cfg.table_terms_fts,
 206:                         tissue, k=min(10, self.cfg.topk_bm25), sources=tissue_sources
 207:                     )
 208:                     labels = [(r.get("label") or "") for r in rows]
 209:                     # Simple tokenization: alpha tokens >= 4 chars, lowercase
 210:                     import re as _re
 211:                     tokens = []
 212:                     for lab in labels:
 213:                         for tok in _re.split(r"[^A-Za-z0-9]+", lab.lower()):
 214:                             if len(tok) >= 4 and not tok.isdigit():
 215:                                 tokens.append(tok)
 216:                     # Frequency rank and take top a few
 217:                     from collections import Counter as _Counter
 218:                     common = [t for t, _ in _Counter(tokens).most_common(8)]
 219:                     bm25_tokens = [t for t in common if t not in (base_query or "").lower()]
 220:             except Exception as e:
 221:                 logger.debug(f"BM25 tissue token derivation skipped due to error: {e}")
 222: 
 223:         # 3) LLM-based context generation
 224:         llm_terms: List[str] = []
 225:         try:
 226:             prompt = CONTEXT_TERMS_PROMPT.format(
 227:                 query=base_query or "",
 228:                 field_name=field_name or "N/A",
 229:                 tissue=tissue or "N/A",
 230:                 organism=organism or "N/A",
 231:             )
 232:             llm_out = self.expansion_llm.text(prompt, temperature=0)
 233:             parsed = parse_llm_json(llm_out, ExpansionResponse)
 234:             if parsed and parsed.context_terms:
 235:                 llm_terms = [t.strip() for t in parsed.context_terms if t and t.strip()]
 236:         except Exception as e:
 237:             logger.debug(f"LLM-based context term generation failed: {e}")
 238: 
 239:         # Combine and truncate to top 5 unique
 240:         combined = _uniq([*llm_terms, *bm25_tokens, *priors])
 241:         if len(combined) > 5:
 242:             combined = combined[:5]
 243: 
 244:         logger.info(
 245:             f"Context terms derived: total={len(combined)} (llm={len(llm_terms)}, bm25={len(bm25_tokens)}, priors={len(priors)})"
 246:         )
 247:         return combined
 248: 
 249:     def __enter__(self):
 250:         """Context manager entry"""
 251:         return self
 252: 
 253:     def __exit__(self, exc_type, exc_val, exc_tb):
 254:         """Context manager exit - ensures proper cleanup"""
 255:         self.close()
 256: 
 257:     def close(self):
 258:         """Explicit cleanup method for resources"""
 259:         # Clean up all thread connections
 260:         if hasattr(self, '_connection_pool'):
 261:             try:
 262:                 for conn in self._connection_pool.values():
 263:                     conn.close()
 264:                 self._connection_pool.clear()
 265:                 logger.info("All SQLite connections closed")
 266:             except Exception as e:
 267:                 logger.warning(f"⚠️ Error closing SQLite connections: {e}")
 268: 
 269:         if hasattr(self, 'executor'):
 270:             try:
 271:                 self.executor.shutdown(wait=True)
 272:                 logger.info("ThreadPoolExecutor shutdown (waited for completion)")
 273:             except Exception as e:
 274:                 logger.warning(f"⚠️ Error shutting down executor: {e}")
 275: 
 276:     def __del__(self):
 277:         """Fallback cleanup - not guaranteed to be called"""
 278:         self.close()
 279: 
 280:     def _dense_search_batch(self, queries: List[str], k: Optional[int] = None) -> List[str]:
 281:         """Batch version of dense search for better performance"""
 282:         if not queries:
 283:             return []
 284: 
 285:         # Batch embed all queries at once
 286:         embeddings = self.embed_fn(queries)
 287:         query_vectors = np.array(embeddings, dtype=np.float32)
 288: 
 289:         # Batch search
 290:         search_k = k if k is not None else self.cfg.topk_dense
 291:         batch_results = self.faiss.search(query_vectors, search_k)
 292: 
 293:         # Flatten results from all queries
 294:         all_ids = []
 295:         for query_results in batch_results:
 296:             all_ids.extend(query_results)
 297: 
 298:         return all_ids
 299: 
 300:     def _dense_search_dual(
 301:         self,
 302:         base_queries: List[str],
 303:         ctx_queries: List[str] | None,
 304:         k: Optional[int] = None,
 305:     ) -> tuple[List[str], List[str]]:
 306:         """Run a single FAISS search for base + context queries and split results.
 307: 
 308:         Returns a pair of flattened, deduped ID lists: (dense_ids, dense_ctx_ids).
 309:         """
 310:         bq = base_queries or []
 311:         cq = ctx_queries or []
 312:         if not bq and not cq:
 313:             return [], []
 314: 
 315:         # Embed all queries at once
 316:         combined = bq + cq
 317:         embeddings = self.embed_fn(combined)
 318:         query_vectors = np.array(embeddings, dtype=np.float32)
 319: 
 320:         search_k = k if k is not None else self.cfg.topk_dense
 321:         batch_results = self.faiss.search(query_vectors, search_k)
 322: 
 323:         base_n = len(bq)
 324:         base_results = batch_results[:base_n]
 325:         ctx_results = batch_results[base_n:] if cq else []
 326: 
 327:         dense_ids: List[str] = []
 328:         for r in base_results:
 329:             dense_ids.extend(r)
 330:         dense_ctx_ids: List[str] = []
 331:         for r in ctx_results:
 332:             dense_ctx_ids.extend(r)
 333: 
 334:         return _uniq(dense_ids), _uniq(dense_ctx_ids)
 335: 
 336:     def get_available_ontologies(self) -> List[str]:
 337:         """List unique ontology IDs (new schema)."""
 338:         conn = self.get_connection()
 339:         cur = conn.cursor()
 340:         cur.execute(f"SELECT DISTINCT ontology_id FROM {self.cfg.table_terms} ORDER BY ontology_id")
 341:         sources = [row[0] for row in cur.fetchall()]
 342:         return sources
 343: 
 344: 
 345: 
 346:     def query(
 347:         self,
 348:         query: str,
 349:         field_name: str,
 350:         organism: str,
 351:         tissue: str,
 352:         n_expansions: Optional[int] = None,
 353:         topk_final: Optional[int] = None,
 354:         return_trace: Optional[bool] = None,
 355:         topk_exact: Optional[int] = None,
 356:         topk_bm25: Optional[int] = None,
 357:         topk_dense: Optional[int] = None,
 358:         rrf_k: Optional[float] = None,
 359:         num_choices: Optional[int] = None,
 360:         exact_only: bool = False,
 361:         graph_depth: int | None = None,
 362:         rerank_after_graph: bool = True,
 363:     ) -> Dict[str, Any]:
 364:         # Increment request count for metrics
 365:         self._request_count += 1
 366: 
 367:         # Direct compute (no caching)
 368:         return self._query_internal(
 369:             query, field_name, organism, tissue, n_expansions,
 370:             topk_final, return_trace,
 371:             topk_exact, topk_bm25, topk_dense, rrf_k, num_choices,
 372:             exact_only, graph_depth, rerank_after_graph
 373:         )
 374: 
 375:     def _query_internal(
 376:         self,
 377:         query: str,
 378:         field_name: str,
 379:         organism: str,
 380:         tissue: str,
 381:         n_expansions: Optional[int] = None,
 382:         topk_final: Optional[int] = None,
 383:         return_trace: Optional[bool] = None,
 384:         topk_exact: Optional[int] = None,
 385:         topk_bm25: Optional[int] = None,
 386:         topk_dense: Optional[int] = None,
 387:         rrf_k: Optional[float] = None,
 388:         num_choices: Optional[int] = None,
 389:         exact_only: bool = False,
 390:         graph_depth: int | None = None,
 391:         rerank_after_graph: bool = True,
 392:     ) -> Dict[str, Any]:
 393:         cfg = self.cfg
 394: 
 395:         logger.info(f"Processing query: '{query}'")
 396:         timings: Dict[str, float] = {}
 397:         t0 = time.monotonic()
 398: 
 399:         # Override config with per-request parameters
 400:         n_expansions = n_expansions if n_expansions is not None else cfg.n_expansions
 401:         topk_final = topk_final if topk_final is not None else cfg.topk_final
 402:         topk_exact_v = topk_exact if topk_exact is not None else cfg.topk_exact
 403:         topk_bm25_v = topk_bm25 if topk_bm25 is not None else cfg.topk_bm25
 404:         topk_dense_v = topk_dense if topk_dense is not None else cfg.topk_dense
 405:         rrf_k_v = rrf_k if rrf_k is not None else cfg.rrf_k
 406: 
 407:         # Normalize field and organism inputs to canonical names for routing
 408:         field_name = normalize_field_name(field_name) or field_name
 409:         organism = normalize_organism(organism) or organism
 410: 
 411:         # Field/organism-driven ontology scoping if not explicitly provided
 412:         auto_scope = allowed_ontologies_for(field_name, organism)
 413:         ontology_filter = auto_scope
 414: 
 415:         # Normalize obvious abbreviations before expansion/retrieval
 416:         _orig_query = query
 417:         # Normalize marker suffixes for cell marker expressions (e.g., CD25+)
 418:         if field_name and field_name.lower() == "cell_type":
 419:             query = normalize_marker_suffixes(query) or query
 420:         # Apply user-provided abbreviations map
 421:         query = self._expand_abbreviations(query, field_name)
 422: 
 423:         trace = {"query": _orig_query, "expansions": [], "candidates": {}, "fusion": [], "disambiguation": {}}
 424:         if query != _orig_query:
 425:             trace["normalized_query"] = query
 426: 
 427:         queries = [query]
 428:         # Derive context terms first (used to guide expansion and retrieval)
 429:         context_terms: List[str] = self._derive_context_terms(query, field_name, tissue, organism)
 430: 
 431:         # Early abstain short-circuit to avoid unnecessary LLM calls/costs
 432:         _abstain_early, _reason_early = should_abstain(query)
 433:         if _abstain_early:
 434:             logger.info(f"Early abstain on query due to no-value indicator: '{query}'")
 435:             trace = {"query": query, "expansions": [], "candidates": {}, "fusion": [], "disambiguation": {}}
 436:             payload = {"results": [], "chosen": {"reason": _reason_early or f"Query '{query}' marked for abstain"}}
 437:             if return_trace:
 438:                 payload["trace"] = trace
 439:             return payload
 440: 
 441:         timings["normalize+context_ms"] = (time.monotonic() - t0) * 1000
 442:         t_exp = time.monotonic()
 443:         if (not cfg.retrieval_only) and cfg.enable_expansion and n_expansions > 0 and not exact_only:
 444:             logger.info(f"Generating {n_expansions} query expansions...")
 445:             # Use the resolved n_expansions for this request
 446:             n_expansions = n_expansions or cfg.n_expansions
 447:             guidance = get_field_guidance(field_name)
 448:             guidance_block = ""
 449:             if guidance:
 450:                 guidance_block = (
 451:                     "Field-Specific Guidance\n"
 452:                     f"- Semantic Constraints: {guidance.get('semantic_constraints','')}\n"
 453:                     f"- Expansion Focus: {guidance.get('expansion_focus','')}\n"
 454:                     f"- Context Priority: {guidance.get('context_priority','')}\n"
 455:                     f"- Avoid: {guidance.get('avoid','')}\n"
 456:                 )
 457:             prompt = QUERY_EXPANSION_PROMPT.format(
 458:                 n=n_expansions,
 459:                 query=query,
 460:                 field_name=field_name or "N/A",
 461:                 tissue=tissue or "N/A",
 462:                 organism=organism or "N/A",
 463:                 context_terms=", ".join(context_terms) if context_terms else "[]",
 464:                 semantic_constraints=guidance.get('semantic_constraints', ''),
 465:                 expansion_focus=guidance.get('expansion_focus', ''),
 466:                 context_priority=guidance.get('context_priority', ''),
 467:                 avoid=guidance.get('avoid', ''),
 468:             )
 469: 
 470:             # Generate expansions via LLM (resilient)
 471:             expansions: List[str] = []
 472:             try:
 473:                 exp_text = self.expansion_llm.text(prompt, temperature=0)
 474:                 parsed = parse_llm_json(exp_text, ExpansionResponse)
 475:                 expansions = [ln.strip() for ln in (parsed.expansions if parsed else []) if ln.strip()]
 476:                 # Merge any LLM-suggested context terms with derived ones
 477:                 llm_ctx = [t.strip() for t in (parsed.context_terms if parsed else []) if t.strip()]
 478:                 if llm_ctx:
 479:                     context_terms = _uniq((context_terms or []) + llm_ctx)[:5]
 480:             except Exception as e:
 481:                 logger.warning(f"Expansion LLM failed, proceeding without expansions: {e}")
 482:             logger.info(f"Generated {len(expansions)} expansions and {len(context_terms)} context terms")
 483: 
 484:             queries.extend(expansions[:n_expansions])
 485:             trace["expansions"] = expansions[:n_expansions]
 486:             if context_terms:
 487:                 trace["context_terms"] = context_terms
 488:             logger.info(f"Total expansions: {len(expansions[:n_expansions])}")
 489: 
 490:         timings["expansion_ms"] = (time.monotonic() - t_exp) * 1000
 491: 
 492:         q_norms = list({_normalize(q) for q in queries})
 493:         logger.info(f"Processing {len(queries)} queries (including {len(q_norms)} unique normalized variants)")
 494: 
 495:         # --- Parallel Retrieval (base + context channels) ---
 496:         logger.info("Starting retrieval across exact, BM25(base/ctx), dense(base), and dense_full(intent)...")
 497:         t_ret = time.monotonic()
 498:         exact_future = self.executor.submit(
 499:             lambda: [h["id"] for h in search_exact(self.get_connection(), cfg.table_terms, cfg.table_terms_fts, q_norms, topk_exact_v, sources=ontology_filter)]
 500:         )
 501:         bm25_future = None if exact_only else self.executor.submit(
 502:             lambda: [h["id"] for q in queries for h in search_bm25(self.get_connection(), cfg.table_terms, cfg.table_terms_fts, q, topk_bm25_v, sources=ontology_filter)]
 503:         )
 504:         # Context-enhanced BM25 channel: append derived context terms to each query
 505:         ctx_queries: List[str] = []
 506:         if (not exact_only) and context_terms:
 507:             ctx_hint = " ".join(context_terms)
 508:             ctx_queries = [f"{q} {ctx_hint}".strip() for q in queries]
 509: 
 510:         # Dense base channel (queries + expansions)
 511:         dense_base_future = None if exact_only else self.executor.submit(
 512:             lambda: self._dense_search_batch(queries, k=topk_dense_v)
 513:         )
 514:         # Dense intent channel (single intent string)
 515:         intent_text = self._build_intent_text(query, field_name, organism, tissue, queries, context_terms)
 516:         intent_vec = None
 517:         dense_full_future = None
 518:         if not exact_only:
 519:             try:
 520:                 intent_vec_np = np.array(self.embed_fn([intent_text]), dtype=np.float32)
 521:                 intent_vec = intent_vec_np[0]
 522:                 dense_full_future = self.executor.submit(
 523:                     lambda: self.faiss.search(intent_vec_np, topk_dense_v)[0]
 524:                 )
 525:             except Exception as e:
 526:                 logger.debug(f"Intent channel embedding/search skipped: {e}")
 527:         bm25_ctx_future = None if (exact_only or not ctx_queries) else self.executor.submit(
 528:             lambda: [h["id"] for q in ctx_queries for h in search_bm25(self.get_connection(), cfg.table_terms, cfg.table_terms_fts, q, topk_bm25_v, sources=ontology_filter)]
 529:         )
 530: 
 531:         exact_ids = _uniq(exact_future.result())
 532:         bm25_ids = _uniq(bm25_future.result()) if bm25_future else []
 533:         dense_ids = _uniq(dense_base_future.result()) if dense_base_future else []
 534:         dense_full_ids = _uniq(dense_full_future.result()) if dense_full_future else []
 535:         bm25_ctx_ids = _uniq(bm25_ctx_future.result()) if bm25_ctx_future else []
 536: 
 537:         # Post-filter FAISS results by ontology_id if filter is applied
 538:         if ontology_filter and (dense_ids or dense_full_ids):
 539:             cur = self.get_connection().cursor()
 540:             def _post_filter(ids: List[str]) -> List[str]:
 541:                 if not ids:
 542:                     return ids
 543:                 qmarks = ",".join("?" for _ in ids)
 544:                 cur.execute(
 545:                     f"SELECT curie FROM {cfg.table_terms} WHERE curie IN ({qmarks}) AND ontology_id IN ({','.join('?' for _ in ontology_filter)})",
 546:                     ids + ontology_filter,
 547:                 )
 548:                 valid = {row[0] for row in cur.fetchall()}
 549:                 return [i for i in ids if i in valid]
 550:             dense_ids = _post_filter(dense_ids)
 551:             dense_full_ids = _post_filter(dense_full_ids)
 552: 
 553:         # Guardrail: Also restrict by CURIE prefix mapping to avoid malformed ontology_id entries
 554:         if ontology_filter:
 555:             try:
 556:                 from .schema_policies import allowed_curie_prefixes
 557:                 prefixes = allowed_curie_prefixes(ontology_filter)
 558:             except Exception:
 559:                 prefixes = None
 560:             if prefixes:
 561:                 def _by_prefix(ids: List[str]) -> List[str]:
 562:                     return [i for i in ids if any(i.startswith(p) for p in prefixes)]
 563:                 exact_ids = _by_prefix(exact_ids)
 564:                 bm25_ids = _by_prefix(bm25_ids)
 565:                 dense_ids = _by_prefix(dense_ids)
 566:                 bm25_ctx_ids = _by_prefix(bm25_ctx_ids)
 567:                 dense_full_ids = _by_prefix(dense_full_ids)
 568: 
 569:         trace["candidates"] = {
 570:             "exact": exact_ids,
 571:             "bm25": bm25_ids,
 572:             "dense": dense_ids,
 573:             "bm25_ctx": bm25_ctx_ids,
 574:             "dense_full": dense_full_ids,
 575:         }
 576:         timings["retrieval_ms"] = (time.monotonic() - t_ret) * 1000
 577:         if ontology_filter:
 578:             trace["ontology_filter"] = ontology_filter
 579: 
 580:         # --- Fusion ---
 581:         # Combine channels with reciprocal rank fusion using configured weights.
 582:         logger.info("Fusing results from base/context channels...")
 583:         # --- Field-Aware RRF Weights (Phase 2 Enhancement) ---
 584:         def get_field_aware_weights(field_name: str) -> Dict[str, float]:
 585:             """Get field-specific RRF weights based on field characteristics."""
 586:             field_lower = (field_name or "").lower()
 587: 
 588:             # Assay fields: boost exact matches (version numbers, specific protocols)
 589:             if field_lower in {"assay", "assay_type", "protocol"}:
 590:                 return {
 591:                     "exact": 1.5,  # Boost exact for version matching
 592:                     "bm25": 0.9,   # Good for keyword matching
 593:                     "dense": 0.4   # Less important for assays
 594:                 }
 595: 
 596:             # Cell type fields: boost dense search (semantic similarity important)
 597:             elif field_lower in {"cell_type", "celltype", "cell"}:
 598:                 return {
 599:                     "exact": 1.0,  # Standard weight
 600:                     "bm25": 0.7,   # Reduced for cell types
 601:                     "dense": 1.2   # Boost dense for semantic matching
 602:                 }
 603: 
 604:             # Disease fields: balanced approach
 605:             elif field_lower in {"disease", "condition", "pathology"}:
 606:                 return {
 607:                     "exact": 1.2,  # Slight boost for exact disease terms
 608:                     "bm25": 0.8,   # Good for disease synonyms
 609:                     "dense": 0.8   # Balanced semantic matching
 610:                 }
 611: 
 612:             # Default weights for other fields
 613:             else:
 614:                 return {
 615:                     "exact": 1.0,
 616:                     "bm25": 0.8,
 617:                     "dense": 0.6,
 618:                 }
 619: 
 620:         # Start with config weights, then apply field-aware overrides
 621:         weights = dict(cfg.rrf_weights)
 622: 
 623:         # Get field-aware weights and apply them
 624:         from .fusion_weights import field_aware_weights
 625:         field_weights = field_aware_weights(field_name)
 626:         weights.update(field_weights)
 627: 
 628:         # Add defaults for context channels based on their base types
 629:         if "bm25_ctx" not in weights:
 630:             weights["bm25_ctx"] = weights.get("bm25", 0.8) * 0.9
 631:         if "dense_full" not in weights:
 632:             weights["dense_full"] = weights.get("dense", 0.6) * 1.0
 633: 
 634:         # If exact matches exist, upweight exact slightly for this query
 635:         if exact_ids:
 636:             weights["exact"] = weights.get("exact", 1.0) * 1.2
 637: 
 638:         logger.info(f"Field-aware weights for '{field_name}': {weights}")
 639:         channel_rankings = {"exact": exact_ids}
 640:         if bm25_ids:
 641:             channel_rankings["bm25"] = bm25_ids
 642:         if dense_ids:
 643:             channel_rankings["dense"] = dense_ids
 644:         if bm25_ctx_ids:
 645:             channel_rankings["bm25_ctx"] = bm25_ctx_ids
 646:         if 'dense_full_ids' in locals() and dense_full_ids:
 647:             channel_rankings["dense_full"] = dense_full_ids
 648:         t_fuse = time.monotonic()
 649:         fused = rrf_fuse(channel_rankings, k=rrf_k_v, weights=weights)[:topk_final]
 650:         trace["fusion"] = fused
 651:         logger.info(f"Fusion complete: {len(fused)} candidates ranked by RRF")
 652:         timings["fusion_ms"] = (time.monotonic() - t_fuse) * 1000
 653: 
 654:         # Log contribution by channel
 655:         try:
 656:             fused_ids_set = {fid for fid, _ in fused}
 657:             contrib = {k: len(set(v).intersection(fused_ids_set)) for k, v in trace["candidates"].items() if v}
 658:             logger.info(f"Channel contributions to fused top-k: {contrib}")
 659:         except Exception:
 660:             pass
 661: 
 662:         # Decide on GRAPH depth (auto mode or explicit override)
 663:         eff_graph_depth = 0
 664:         try:
 665:             # Respect explicit override if provided (including 0)
 666:             if graph_depth is not None:
 667:                 eff_graph_depth = int(graph_depth)
 668:             else:
 669:                 mode = (cfg.graph_mode or "auto").lower()
 670:                 if mode == "on":
 671:                     eff_graph_depth = max(1, cfg.graph_auto_depth)
 672:                 elif mode == "auto":
 673:                     # Only consider for conservative fields
 674:                     allow_fields = {f.strip().lower() for f in (cfg.graph_auto_fields or [])}
 675:                     if field_name and field_name.lower() in allow_fields and not exact_ids:
 676:                         # Estimate confidence from fused scores (pre-graph): normalize to [0,1]
 677:                         if fused:
 678:                             scores = [s for _, s in fused]
 679:                             mx, mn = max(scores), min(scores)
 680:                             span = (mx - mn) or 1.0
 681:                             confs = [(s - mn) / span for s in scores]
 682:                             top1 = confs[0] if confs else 0.0
 683:                             top3_mean = sum(confs[:3]) / min(3, len(confs)) if confs else 0.0
 684:                             if (top1 < cfg.graph_top1_min) or (top3_mean < cfg.graph_top3_mean_min):
 685:                                 eff_graph_depth = max(1, cfg.graph_auto_depth)
 686:         except Exception:
 687:             eff_graph_depth = 0
 688: 
 689:         # Graph expansion + second RRF (with distance decay)
 690:         t_graph = time.monotonic()
 691:         if eff_graph_depth > 0 and rerank_after_graph:
 692:             seed_ids = [fid for fid, _ in fused]
 693:             neighbors = compute_graph_neighbors(self.get_connection(), cfg.table_terms, seed_ids, eff_graph_depth)
 694:             if neighbors:
 695:                 # Build distance-decayed ranked list for graph neighbors
 696:                 graph_ranked_list = []
 697:                 for nid, depth in neighbors.items():
 698:                     score = 1.0 / (1.0 + depth)
 699:                     graph_ranked_list.append((nid, score))
 700:                 graph_ranked_list.sort(key=lambda x: x[1], reverse=True)
 701:                 graph_ids_only = [nid for nid, _ in graph_ranked_list]
 702:                 fused2 = rrf_fuse(
 703:                     {"fused": [fid for fid, _ in fused], "graph": graph_ids_only},
 704:                     k=rrf_k_v,
 705:                     weights={"fused": 1.0, "graph": float(getattr(cfg, 'graph_weight', 0.7))},
 706:                 )[:topk_final]
 707:                 # Log that AUTO/ON graph rerank was applied for transparency
 708:                 try:
 709:                     mode = (cfg.graph_mode or "auto").lower()
 710:                     logger.info(f"Graph rerank applied (mode={mode}, depth={eff_graph_depth}, graph_weight={getattr(cfg,'graph_weight',0.7)})")
 711:                 except Exception:
 712:                     pass
 713:                 trace["fusion_graph"] = fused2
 714:                 fused = fused2
 715:         timings["graph_ms"] = (time.monotonic() - t_graph) * 1000
 716: 
 717:         ids = [fid for fid, _ in fused]
 718:         if not ids:
 719:             logger.warning("No candidates found after fusion")
 720:             payload = {"results": [], "chosen": None}
 721:             if return_trace:
 722:                 payload["trace"] = trace
 723:             return payload
 724: 
 725:         # --- Metadata Hydration ---
 726:         t_hydrate = time.monotonic()
 727:         logger.info("Hydrating metadata for ranked candidates...")
 728:         cur = self.get_connection().cursor()
 729:         qmarks = ",".join("?" for _ in ids)
 730:         meta = {}
 731:         cur.execute(
 732:             f"SELECT curie, label, definition, ontology_id, iri, synonyms_exact, synonyms_related, synonyms_broad, synonyms_narrow, xrefs, comments, is_obsolete, term_doc "
 733:             f"FROM {cfg.table_terms} WHERE curie IN ({qmarks})",
 734:             ids,
 735:         )
 736:         for row in cur.fetchall():
 737:             (
 738:                 _id,
 739:                 _label,
 740:                 _definition,
 741:                 _source,
 742:                 _iri,
 743:                 _sx,
 744:                 _sr,
 745:                 _sb,
 746:                 _sn,
 747:                 _xr,
 748:                 _cm,
 749:                 _obsolete,
 750:                 _term_doc,
 751:             ) = row
 752:             # Skip obsolete terms entirely
 753:             if _obsolete:
 754:                 continue
 755:             def _split_pipe(x):
 756:                 if not x:
 757:                     return None
 758:                 vals = [t.strip() for t in str(x).split("|") if t.strip()]
 759:                 return vals or None
 760:             syn_exact = _split_pipe(_sx)
 761:             syn_related = _split_pipe(_sr)
 762:             syn_broad = _split_pipe(_sb)
 763:             xrefs = _split_pipe(_xr)
 764:             comments = _cm
 765:             meta[_id] = {
 766:                 "label": _label,
 767:                 "definition": _definition,
 768:                 "source": _source,
 769:                 "iri": _iri,
 770:                 "synonyms_exact": syn_exact,
 771:                 "synonyms_related": syn_related,
 772:                 "synonyms_broad": syn_broad,
 773:                 "synonyms_generic": None,
 774:                 "alt_ids": None,
 775:                 "xrefs": xrefs,
 776:                 "namespace": None,
 777:                 "subsets": None,
 778:                 "comments": comments,
 779:                 "parents_is_a": None,
 780:                 "abstracts": None,
 781:                 "term_doc": _term_doc,
 782:             }
 783: 
 784:         ranked = []
 785:         for fid, fscore in fused:
 786:             if fid in meta:
 787:                 ranked.append({"id": fid, **meta[fid], "fusion_score": fscore})
 788: 
 789:         timings["hydrate_ms"] = (time.monotonic() - t_hydrate) * 1000
 790:         logger.info(f"Metadata hydration complete: {len(ranked)} candidates with full information")
 791: 
 792:         # --- Pre-LLM Hard Constraints (Phase 1 Critical Fix) ---
 793:         logger.info("Applying pre-LLM hard constraints...")
 794: 
 795:         def _make_label_blob(r: dict) -> str:
 796:             """Combine all text fields for conflict checking"""
 797:             parts = [r.get("label") or "", r.get("definition") or ""]
 798:             for synfield in ("synonyms_exact", "synonyms_related", "synonyms_broad"):
 799:                 parts.extend(r.get(synfield) or [])
 800:             return " ".join(parts)
 801: 
 802:         # Check for immediate abstain conditions
 803:         _abstain, _reason = should_abstain(query)
 804:         if _abstain:
 805:             logger.info(f"Abstaining on query due to no-value indicator: '{query}'")
 806:             abstain_reason = _reason or f"Query '{query}' marked for abstain"
 807:             payload = {"results": [], "chosen": {"reason": abstain_reason}}
 808:             if return_trace:
 809:                 payload["trace"] = trace
 810:             return payload
 811: 
 812:         # Apply hard filters for cell types
 813:         original_count = len(ranked)
 814:         if field_name.lower() in {"cell_type"} and (tissue or organism):
 815:             kept = []
 816:             for r in ranked:
 817:                 blob = _make_label_blob(r)
 818:                 if tissue and context_violation(blob, tissue):
 819:                     logger.debug(f"Filtered {r['id']} due to tissue conflict: {r.get('label', '')}")
 820:                     continue
 821:                 if organism and species_violation(blob, organism):
 822:                     logger.debug(f"Filtered {r['id']} due to species conflict: {r.get('label', '')}")
 823:                     continue
 824:                 kept.append(r)
 825:             ranked = kept or ranked  # only drop if we still have something
 826: 
 827:         # Domain-specific whitelists
 828:         field_lower = field_name.lower()
 829: 
 830:         # Sex field: only allow canonical terms
 831:         if field_lower == "sex":
 832:             allowed = {"male", "female"}
 833:             def _is_allowed(r):
 834:                 label = (r.get("label") or "").lower()
 835:                 syns = [s.lower() for s in (r.get("synonyms_exact") or [])]
 836:                 return any(x in allowed for x in [label, *syns])
 837:             new = [r for r in ranked if _is_allowed(r)]
 838:             ranked = new or ranked
 839: 
 840:         # Disease field: prioritize PATO:0000461 for healthy/normal
 841:         if field_lower == "disease":
 842:             query_lower = (_orig_query or "").lower()
 843:             if any(k in query_lower for k in ["healthy", "normal", "control", "no disease"]):
 844:                 for r in ranked:
 845:                     if r["id"] == "PATO:0000461":
 846:                         ranked = [r] + [x for x in ranked if x["id"] != "PATO:0000461"]
 847:                         break
 848: 
 849:         # Ethnicity field: prefer continental HANCESTRO
 850:         if field_lower == "self_reported_ethnicity":
 851:             def _continental(r):
 852:                 blob = _make_label_blob(r).lower()
 853:                 return any(tok in blob for tok in ["european", "african", "east asian", "south asian", "admixed", "latino", "american"])
 854:             ranked.sort(key=lambda r: (not _continental(r), -r.get("retrieval_confidence", 0.0)))
 855: 
 856:         filtered_count = len(ranked)
 857:         if filtered_count < original_count:
 858:             logger.info(f"Hard constraints filtered {original_count - filtered_count} candidates, {filtered_count} remaining")
 859: 
 860:         # Check if no candidates remain after filtering
 861:         if not ranked:
 862:             logger.info("No candidates remain after hard constraint filtering - returning abstain")
 863:             payload = {"results": [], "chosen": {"reason": "No compatible candidates after filtering"}}
 864:             if return_trace:
 865:                 payload["trace"] = trace
 866:             return payload
 867: 
 868:         # --- Re-ranking with Contextual Soft Boosts ---
 869:         t_rerank = time.monotonic()
 870:         logger.info("Re-ranking candidates with contextual soft boosts...")
 871:         exact_set = set(exact_ids)
 872: 
 873:         # Semantic intent cosine rerank using FAISS rescore vectors (no term re-embedding)
 874:         if self.cfg.enable_semantic_intent_rerank and 'intent_vec' in locals() and intent_vec is not None and ranked:
 875:             try:
 876:                 cand_ids = [r["id"] for r in ranked]
 877:                 sim_map = self.faiss.score_ids(intent_vec, cand_ids)
 878:                 if sim_map:
 879:                     sims = [sim_map.get(r["id"], 0.0) for r in ranked]
 880:                     s_min, s_max = min(sims), max(sims)
 881:                     denom = (s_max - s_min) or 1.0
 882:                     for r, s in zip(ranked, sims):
 883:                         score01 = (s - s_min) / denom
 884:                         r["fusion_score"] += self.cfg.semantic_intent_weight * float(score01)
 885:                     logger.info("Applied semantic intent cosine rerank to fused candidates")
 886:             except Exception as e:
 887:                 logger.debug(f"Semantic intent rerank skipped due to error: {e}")
 888: 
 889:         apply_soft_boosts(ranked, cfg, field_name, _orig_query or "", context_terms or [], exact_set)
 890: 
 891:         ranked.sort(key=lambda x: x["fusion_score"], reverse=True)
 892:         timings["rerank_ms"] = (time.monotonic() - t_rerank) * 1000
 893: 
 894:         # Calculate confidence scores
 895:         if ranked:
 896:             max_score = max(r["fusion_score"] for r in ranked)
 897:             min_score = min(r["fusion_score"] for r in ranked)
 898:             span = (max_score - min_score) or 1.0
 899:             for r in ranked:
 900:                 r["retrieval_confidence"] = float((r["fusion_score"] - min_score) / span)
 901: 
 902:         # Disambiguation via LLM
 903:         chosen = None
 904:         reason = None
 905:         llm_conf = None
 906:         llm_abstained = False
 907:         t_llm = time.monotonic()
 908:         if ranked and not cfg.retrieval_only:
 909:             # Prepare candidates block
 910:             cand_lines = []
 911:             for r in ranked[: topk_final or len(ranked)]:
 912:                 cand_lines.append(f"{r['id']} | {r.get('label') or ''} | {r.get('source') or ''} | {r.get('retrieval_confidence', 0.0):.3f} | { (r.get('definition') or '')[:200] }")
 913:             candidates_block = "\n".join(cand_lines)
 914:             guidance = get_field_guidance(field_name)
 915:             guidance_block = ""
 916:             if guidance:
 917:                 guidance_block = (
 918:                     "Field-Specific Guidance\n"
 919:                     f"- Semantic Constraints: {guidance.get('semantic_constraints','')}\n"
 920:                     f"- Context Priority: {guidance.get('context_priority','')}\n"
 921:                     f"- Avoid: {guidance.get('avoid','')}\n"
 922:                     f"- Disambiguation Rules: {guidance.get('disambiguation_rules','')}\n"
 923:                 )
 924:             prompt = DISAMBIGUATION_PROMPT.format(
 925:                 query=query,
 926:                 field_name=field_name or "N/A",
 927:                 tissue=tissue or "N/A",
 928:                 candidates_block=candidates_block,
 929:                 disambiguation_rules=guidance.get('disambiguation_rules', ''),
 930:             )
 931:             try:
 932:                 out = self.disamb_llm.text(prompt, temperature=0)
 933:                 parsed = parse_llm_json(out, DisambiguationResponse)
 934: 
 935:                 # Validate LLM response (Phase 1 Critical Fix)
 936:                 if parsed and parsed.chosen_id:
 937:                     # Check if chosen_id is in candidate list
 938:                     valid_choice = any(r["id"] == parsed.chosen_id for r in ranked)
 939:                     if valid_choice:
 940:                         for r in ranked:
 941:                             if r["id"] == parsed.chosen_id:
 942:                                 chosen = dict(r)
 943:                                 reason = parsed.reason
 944:                                 llm_conf = parsed.llm_confidence
 945:                                 break
 946:                     else:
 947:                         # Treat out-of-candidate selection as an abstain to avoid misleading fallbacks
 948:                         llm_abstained = True
 949:                         reason = parsed.reason or f"LLM selected ID not in candidates: {parsed.chosen_id}"
 950:                         logger.warning(f"LLM chose out-of-candidate ID '{parsed.chosen_id}', abstaining")
 951:                 elif parsed and parsed.chosen_id is None:
 952:                     # LLM explicitly abstained; record reason but keep candidates and trace
 953:                     llm_abstained = True
 954:                     reason = parsed.reason or "LLM chose to abstain"
 955:             except Exception as e:
 956:                 logger.warning(f"Error parsing LLM disambiguation response: {e}")
 957:                 pass
 958: 
 959:         timings["llm_ms"] = (time.monotonic() - t_llm) * 1000 if not cfg.retrieval_only else 0.0
 960:         # Fallback to top-1 if LLM did not choose AND did not abstain (or in retrieval-only mode)
 961:         if not chosen and ranked and (cfg.retrieval_only or not llm_abstained):
 962:             chosen = dict(ranked[0])
 963:         if chosen is not None:
 964:             if reason is not None:
 965:                 chosen["reason"] = reason
 966:             if llm_conf is not None:
 967:                 chosen["llm_confidence"] = llm_conf
 968:         elif llm_abstained and reason:
 969:             # Surface abstain reason for downstream formatting
 970:             chosen = {"reason": reason}
 971: 
 972:         # Alternatives if requested
 973:         alternatives: List[Dict[str, Any]] = []
 974:         if chosen and num_choices and num_choices > 0:
 975:             alternatives = [
 976:                 {k: v for k, v in r.items() if k != "fusion_score"}
 977:                 for r in ranked[1 : 1 + num_choices]
 978:             ]
 979: 
 980:         # Assemble output
 981:         result_payload = {
 982:             "results": [
 983:                 {k: v for k, v in r.items() if k != "fusion_score"}
 984:                 for r in ranked
 985:             ]
 986:         }
 987:         if chosen:
 988:             result_payload["chosen"] = chosen
 989:         if alternatives:
 990:             result_payload["alternatives"] = alternatives
 991:         if return_trace:
 992:             trace["timings_ms"] = {k: round(v, 2) for k, v in timings.items()}
 993:             result_payload["trace"] = trace
 994:         return result_payload
 995: """BOND pipeline orchestrator.
 996: 
 997: This module implements the end-to-end normalization flow used by the CLI and
 998: API:
 999:   1) Field-specific abbreviation normalization (assets/abbreviations.json)
1000:   2) LLM query expansion + context term generation (prompts.py + field_guidance)
1001:   3) Parallel multi-channel retrieval (Exact FTS, BM25 FTS, FAISS dense)
1002:   4) Reciprocal Rank Fusion (optional second RRF after graph expansion)
1003:   5) Metadata hydration from SQLite (filters obsolete terms)
1004:   6) Contextual re-ranking (exact/ontology-prior/context-overlap boosts)
1005:   7) LLM disambiguation with strict, field-specific guidance
1006: 
1007: Graph expansion runs in one of three modes: off | auto | on. In auto mode
1008: (the default), a shallow depth-1 expansion is applied only for conservative
1009: fields (tissue, development_stage, cell_type) when there are no exact matches
1010: and the fused confidence is low. All graph candidates remain scoped to the
1011: field's ontology.
1012: """

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/prompts.py
Size: 92 lines
================================================================================
   1: # bond/prompts.py
   2: 
   3: QUERY_EXPANSION_PROMPT = """
   4: Expand the query "{query}" into exactly {n} concise, high-signal variants. Also propose a short list of context terms.
   5: 
   6: **Query Context:**
   7: - Field: "{field_name}"
   8: - Tissue: "{tissue}"
   9: - Organism: "{organism}"
  10: - Derived Context Terms: {context_terms}
  11: 
  12: **Expansion Rules for Field "{field_name}":**
  13: - Semantic Constraints: {semantic_constraints}
  14: - Expansion Focus: {expansion_focus}
  15: - Context Priority: {context_priority}
  16: - Avoid: {avoid}
  17: - Preserve core query tokens; if an abbreviation is present (e.g., "smg"), expand it (e.g., "submucosal gland").
  18: - Reflect the Tissue and Organism context in the variants when applicable (e.g., lung/airway/bronchial for lung datasets).
  19: - Do not cross organs or systems unless explicitly asked (avoid salivary/mammary/pancreatic for lung unless in the query).
  20: 
  21: **Instructions:**
  22: Return ONLY a JSON object with two fields:
  23: - "expansions": An array of exactly {n} strings.
  24: - "context_terms": An array of up to 5 short tokens/phrases capturing relevant biological context.
  25: """
  26: 
  27: DISAMBIGUATION_PROMPT = """
  28: You are a meticulous biomedical ontology curator. Your sole task is to choose the single best ontology term from the candidates that STRICTLY matches the query and its context.
  29: 
  30: **INPUT:**
  31: - Query: "{query}"
  32: - Field: "{field_name}"
  33: - Tissue Context: "{tissue}"
  34: 
  35: **CANDIDATES (ID | Label | Source | Score | Description):**
  36: {candidates_block}
  37: 
  38: **CRITICAL INSTRUCTIONS:**
  39: You MUST return a candidate ID from the list below. If NO candidate satisfies all rules after applying constraints, set "chosen_id": null.
  40: 
  41: {disambiguation_rules}
  42: - Context enforcement: If a Tissue Context is provided, REJECT any candidate whose label/definition/synonyms indicate an incompatible organ/system (e.g., salivary or mammary ducts for lung; non-respiratory tissues for airway queries).
  43: - Species enforcement: REJECT candidates with species markers (e.g., "(Mmus)") that contradict the organism context.
  44: - Unknown/ambiguous queries: For queries containing "unknown" or "doublet", prefer to set "chosen_id": null rather than guess.
  45: - The retrieval score is the LEAST important factor; use it only to break ties between candidates that already satisfy all rules and context constraints.
  46: 
  47: **ABSTAIN CAPABILITY:**
  48: If no candidate satisfies all rules and constraints, set "chosen_id": null to abstain rather than making an incorrect choice.
  49: 
  50: **FINAL SELECTION:**
  51: Evaluate the candidates against the rules above and select the single best match, or abstain if none qualify.
  52: 
  53: Return ONLY a JSON object with these fields:
  54: - "chosen_id": The single best candidate ID that satisfies all rules, OR null to abstain.
  55: - "reason": A brief, expert rationale explaining WHY the chosen candidate is correct (or why you abstained).
  56: - "llm_confidence": A number in [0,1] indicating your confidence.
  57: """
  58: # bond/prompts.py
  59: 
  60: """Prompt templates used by the expansion and disambiguation LLMs.
  61: 
  62: Placeholders:
  63:   - {query}: raw (or normalized) user query
  64:   - {n}: number of expansions to generate
  65:   - {field_name}: schema field (cell_type, tissue, disease, ...)
  66:   - {tissue}: dataset tissue context (may be "N/A")
  67:   - {semantic_constraints}, {expansion_focus}: field-guided expansion hints
  68:   - {candidates_block}: top-k candidates for disambiguation (id|label|source|score|desc)
  69:   - {disambiguation_rules}: strict, field-specific rules to enforce semantics
  70: 
  71: These strings are rendered in pipeline.py and sent to the LLM provider via
  72: providers.ChatLLM.
  73: """
  74: 
  75: # Context-only prompt for deriving short, high-signal disambiguation hints
  76: CONTEXT_TERMS_PROMPT = """
  77: List 3-5 short, domain-specific context terms to help disambiguate the query for ontology linking.
  78: 
  79: Input:
  80: - Query: "{query}"
  81: - Field: "{field_name}"
  82: - Tissue: "{tissue}"
  83: - Organism: "{organism}"
  84: 
  85: Rules:
  86: - Return concise tokens/phrases (1-3 words), no punctuation or explanations.
  87: - Prefer high-signal biological hints (e.g., anatomical subregions, lineage, markers, qualifiers).
  88: - Do not include the original query tokens; avoid duplicates and overly generic words.
  89: 
  90: Return ONLY JSON:
  91: { "context_terms": ["term1", "term2", "term3"] }
  92: """

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/providers.py
Size: 155 lines
================================================================================
   1: import os
   2: from typing import Callable, List
   3: import time
   4: import numpy as np
   5: 
   6: # Load environment variables from .env file
   7: try:
   8:     from dotenv import load_dotenv
   9:     load_dotenv()
  10: except ImportError:
  11:     # Fallback if python-dotenv is not available
  12:     pass
  13: 
  14: 
  15: 
  16: def _norm(vectors: List[List[float]]) -> List[List[float]]:
  17:     arr = np.asarray(vectors, dtype=np.float32)
  18:     arr /= (np.linalg.norm(arr, axis=1, keepdims=True) + 1e-9)
  19:     return arr.tolist()
  20: 
  21: 
  22: 
  23: def resolve_embeddings(spec: str, batch_size: int = 8, **keys) -> Callable[[List[str]], List[List[float]]]:
  24:     """
  25:     Returns a function: List[str] -> List[List[float]].
  26:     Supported specs:
  27:       - "litellm:<provider/model>" (e.g., litellm:text-embedding-3-small or litellm:openai/text-embedding-3-small)
  28:       - "ollama:<model>" (convenience alias for ollama/ models via LiteLLM)
  29:       - implicit LiteLLM when the spec looks like a provider/model (contains '/')
  30:     Args:
  31:       - batch_size: Default batch size for inference (default: 8). FAISS generation can override with env variable.
  32:     Notes:
  33:       - Do NOT split on ':' generically; Ollama tags like ":latest" are valid model names.
  34:       - Use OLLAMA_API_BASE env var for remote Ollama endpoints (defaults to localhost:11434).
  35:     """
  36:     if spec.startswith("litellm:"):
  37:         provider, model = ("litellm", spec[len("litellm:"):])
  38:     elif spec.startswith("ollama:"):
  39:         # Convenience alias retained for BC (routes to LiteLLM)
  40:         return resolve_embeddings(f"litellm:ollama/{spec.split(':', 1)[1]}", batch_size=batch_size, **keys)
  41:     else:
  42:         # Auto-detect: if spec looks like a LiteLLM model (contains '/'), route via LiteLLM
  43:         provider, model = ("litellm", spec)
  44: 
  45:     if provider == "litellm":
  46:         # Handle Ollama models directly due to LiteLLM endpoint issues
  47:         if model.startswith("ollama/"):
  48:             import requests
  49:             import json
  50: 
  51:             # Extract model name (remove "ollama/" prefix)
  52:             ollama_model = model[7:]  # Remove "ollama/" prefix
  53:             api_base = os.getenv("OLLAMA_API_BASE", "http://localhost:11434")
  54: 
  55:             embed_timeout = int(os.getenv("BOND_EMBED_TIMEOUT", "30"))
  56:             embed_retries = int(os.getenv("BOND_EMBED_RETRIES", "3"))
  57:             def embed(texts: List[str]) -> List[List[float]]:
  58:                 vectors = []
  59:                 for text in texts:
  60:                     last_err = None
  61:                     for attempt in range(embed_retries):
  62:                         try:
  63:                             response = requests.post(
  64:                                 f"{api_base}/api/embeddings",
  65:                                 json={"model": ollama_model, "prompt": text},
  66:                                 headers={"Content-Type": "application/json"},
  67:                                 timeout=embed_timeout,
  68:                             )
  69:                             response.raise_for_status()
  70:                             data = response.json()
  71:                             vectors.append(data["embedding"])
  72:                             last_err = None
  73:                             break
  74:                         except Exception as e:
  75:                             last_err = e
  76:                             time.sleep(0.5 * (2 ** attempt))
  77:                     if last_err is not None:
  78:                         raise RuntimeError(f"Ollama embedding failed for text '{text[:50]}...': {last_err}")
  79:                 return _norm(vectors)
  80:             return embed
  81:         else:
  82:             # OpenAI-format across providers (OpenAI, Azure, Anthropic, Gemini/Vertex, Cohere,
  83:             # Mistral, Groq, AWS Bedrock, NVIDIA NIM, HuggingFace Inference, Voyage, Together, etc.)
  84:             import litellm
  85:             from litellm import embedding as llm_embedding
  86:             # Some providers may not support all params; instruct LiteLLM to drop unknowns
  87:             try:
  88:                 litellm.drop_params = True
  89:             except Exception:
  90:                 pass
  91: 
  92:             api_base = None  # Use provider defaults for non-Ollama models
  93:             embed_timeout = int(os.getenv("BOND_EMBED_TIMEOUT", "30"))
  94:             embed_retries = int(os.getenv("BOND_EMBED_RETRIES", "3"))
  95:             def embed(texts: List[str]) -> List[List[float]]:
  96:                 kwargs = {"model": model, "input": texts, "api_base": api_base, "timeout": embed_timeout, "request_timeout": embed_timeout}
  97:                 kwargs.update(keys)
  98:                 last_err = None
  99:                 for attempt in range(embed_retries):
 100:                     try:
 101:                         resp = llm_embedding(**kwargs)
 102:                         vectors = [item["embedding"] for item in resp["data"]]
 103:                         return _norm(vectors)
 104:                     except Exception as e:
 105:                         last_err = e
 106:                         time.sleep(0.5 * (2 ** attempt))
 107:                 raise RuntimeError(f"Embedding provider failed after retries: {last_err}")
 108:             return embed
 109: 
 110:     raise ValueError(f"Unknown embedding spec: {spec}")
 111: 
 112: class ChatLLM:
 113:     """
 114:     LiteLLM chat completions for all providers.
 115:     Accepts model like "openai/gpt-4o-mini", "anthropic/claude-3-5-sonnet", "google/gemini-1.5-pro",
 116:     "groq/llama-3.1-70b", "azure/gpt-4o-mini", "ollama/llama3", etc.
 117:     """
 118:     def __init__(self, model: str):
 119:         self._model = model
 120:         # LiteLLM for all models
 121:         import litellm
 122:         from litellm import completion
 123:         self._completion = completion
 124:         # Accept both "openai/gpt-4o-mini" and "text-embedding-3-small" style identifiers
 125:         self._wire_model = model.replace(":", "/")
 126:         # Single API base: only honor OLLAMA_API_BASE for ollama/* models
 127:         self._api_base = os.getenv("OLLAMA_API_BASE") if self._wire_model.startswith("ollama/") else None
 128:         # Ensure unknown params are safely dropped
 129:         try:
 130:             litellm.drop_params = True
 131:         except Exception:
 132:             pass
 133: 
 134:     def text(self, prompt: str, temperature: float = 0.0, max_tokens: int = 512) -> str:
 135:         # Use LiteLLM for all models with retry/backoff + timeout
 136:         timeout = int(os.getenv("BOND_LLM_TIMEOUT", "30"))
 137:         max_retries = int(os.getenv("BOND_LLM_RETRIES", "3"))
 138:         kwargs = {
 139:             "model": self._wire_model,
 140:             "messages": [{"role": "user", "content": prompt}],
 141:             "temperature": temperature,
 142:             "max_tokens": max_tokens,
 143:             "api_base": self._api_base,
 144:             "timeout": timeout,
 145:             "request_timeout": timeout,
 146:         }
 147:         last_err = None
 148:         for attempt in range(max_retries):
 149:             try:
 150:                 resp = self._completion(**kwargs)
 151:                 return resp.choices[0].message.content.strip()
 152:             except Exception as e:
 153:                 last_err = e
 154:                 time.sleep(0.5 * (2 ** attempt))
 155:         raise RuntimeError(f"LLM completion failed after retries: {last_err}")

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/rerank.py
Size: 146 lines
================================================================================
   1: from typing import Dict, List, Set
   2: 
   3: 
   4: def _assay_tokens(text: str) -> set[str]:
   5:     t = (text or "").lower()
   6:     feats = set()
   7:     if "10x" in t:
   8:         feats.add("10x")
   9:     if "smart-seq" in t or "smartseq" in t:
  10:         feats.add("smart-seq")
  11:     if "drop-seq" in t or "dropseq" in t or "drop seq" in t:
  12:         feats.add("drop-seq")
  13:     if "cel-seq" in t or "celseq" in t or "cel seq" in t:
  14:         feats.add("cel-seq")
  15:     if "atac" in t:
  16:         feats.add("atac")
  17:     if "rna-seq" in t or "rnaseq" in t or "rna seq" in t:
  18:         feats.add("rna-seq")
  19:     if "spatial" in t or "visium" in t:
  20:         feats.add("spatial")
  21:     if "multiome" in t:
  22:         feats.add("multiome")
  23:     if "snrna" in t:
  24:         feats.add("snrna")
  25:     if "scrna" in t:
  26:         feats.add("scrna")
  27:     if "tcr" in t:
  28:         feats.add("tcr")
  29:     return feats
  30: 
  31: 
  32: def apply_soft_boosts(
  33:     ranked: List[Dict],
  34:     cfg,
  35:     field_name: str,
  36:     query: str,
  37:     context_terms: List[str] | None,
  38:     exact_ids: Set[str],
  39: ) -> None:
  40:     """Apply domain-aware soft boosts to fusion_score in-place.
  41: 
  42:     Includes exact-match, ontology prior, context overlap, term_doc lexical overlap,
  43:     assay version/protocol, language preference, and sex canonical preference.
  44:     """
  45:     # Build context tokens
  46:     context_tokens = {tok for term in (context_terms or []) for tok in term.lower().split()}
  47: 
  48:     # Lexical token set from original query + expansions + context is assembled upstream;
  49:     # here reuse context_tokens for overlap; use term_doc for longer matches separately.
  50: 
  51:     # Assay feature tokens from query
  52:     q_assay_feats = _assay_tokens(query)
  53: 
  54:     for r in ranked:
  55:         # 1) Exact Match Boost
  56:         if r.get("id") in exact_ids:
  57:             r["fusion_score"] += cfg.exact_match_boost
  58: 
  59:         # 2) Ontology Prior Boost
  60:         try:
  61:             from .schema_policies import get_ontology_prior_for_field
  62: 
  63:             primary_ontology = get_ontology_prior_for_field(field_name)
  64:             if primary_ontology and r.get("source") == primary_ontology:
  65:                 r["fusion_score"] += cfg.ontology_prior_boost
  66:         except Exception:
  67:             pass
  68: 
  69:         # 3) Context Overlap Boost (label/definition/synonyms_exact)
  70:         if context_tokens:
  71:             candidate_text = (
  72:                 (r.get("label") or "")
  73:                 + " "
  74:                 + (r.get("definition") or "")
  75:                 + " "
  76:                 + " ".join(r.get("synonyms_exact") or [])
  77:             ).lower()
  78:             candidate_tokens = set(candidate_text.split())
  79:             overlap = len(context_tokens.intersection(candidate_tokens))
  80:             if overlap > 0:
  81:                 r["fusion_score"] += (cfg.context_overlap_boost * overlap)
  82: 
  83:         # 3b) term_doc lexical overlap boost using combined tokens (simple contains)
  84:         try:
  85:             # Build a minimal token set from query and context for term_doc scan
  86:             lex_tokens: set[str] = set()
  87:             for token in (query or "").lower().replace("/", " ").replace("_", " ").split():
  88:                 if len(token) >= 3 and token.isalnum():
  89:                     lex_tokens.add(token)
  90:             for ct in context_terms or []:
  91:                 for token in ct.lower().split():
  92:                     if len(token) >= 3 and token.isalnum():
  93:                         lex_tokens.add(token)
  94:             if lex_tokens and r.get("term_doc"):
  95:                 td = str(r["term_doc"]).lower()
  96:                 hit = sum(1 for t in lex_tokens if t in td)
  97:                 if hit > 0:
  98:                     r["fusion_score"] += (cfg.term_doc_overlap_boost * hit)
  99:         except Exception:
 100:             pass
 101: 
 102:         # 4) Assay version/protocol boosts
 103:         if field_name.lower() in {"assay", "assay_type", "protocol"}:
 104:             candidate_text = (
 105:                 (r.get("label") or "")
 106:                 + " "
 107:                 + (r.get("definition") or "")
 108:                 + " "
 109:                 + " ".join(r.get("synonyms_exact") or [])
 110:             ).lower()
 111:             import re
 112: 
 113:             query_versions = re.findall(r"v(\d+)", (query or "").lower())
 114:             candidate_versions = re.findall(r"v(\d+)", candidate_text)
 115:             if query_versions and candidate_versions and any(qv in candidate_versions for qv in query_versions):
 116:                 r["fusion_score"] += 0.3
 117: 
 118:             cand_feats = _assay_tokens(candidate_text)
 119:             if len(q_assay_feats) >= 2:
 120:                 matched = len(q_assay_feats.intersection(cand_feats))
 121:                 missing = len(q_assay_feats) - matched
 122:                 if matched == len(q_assay_feats):
 123:                     r["fusion_score"] += 0.5
 124:                 else:
 125:                     r["fusion_score"] += 0.1 * matched
 126:                     r["fusion_score"] -= 0.2 * missing
 127: 
 128:         # 5) Language preference: prefer ASCII labels for ASCII queries
 129:         try:
 130:             q_non_ascii = sum(1 for ch in (query or "") if ord(ch) > 127)
 131:             if q_non_ascii == 0:
 132:                 label_text = (r.get("label") or "")
 133:                 label_non_ascii = sum(1 for ch in label_text if ord(ch) > 127)
 134:                 if label_non_ascii > 0:
 135:                     r["fusion_score"] -= 0.5
 136:         except Exception:
 137:             pass
 138: 
 139:         # 6) Sex canonical preference
 140:         if field_name.lower() == "sex":
 141:             lbl = (r.get("label") or "").strip().lower()
 142:             if lbl in {"male", "female"}:
 143:                 r["fusion_score"] += 2.0
 144:             elif " " in lbl:
 145:                 r["fusion_score"] -= 0.2
 146: 

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/rules.py
Size: 191 lines
================================================================================
   1: """Common heuristic rules for BOND pipeline.
   2: 
   3: Includes abstain detection and basic compatibility checks extracted
   4: from the pipeline to keep orchestration code lean.
   5: """
   6: 
   7: from __future__ import annotations
   8: 
   9: import re
  10: from typing import Tuple
  11: 
  12: 
  13: # Precompiled, token-aware patterns for abstain triggers (case-insensitive)
  14: _ABSTAIN_PATTERNS = [
  15:     re.compile(r"\bunknown\b", re.IGNORECASE),
  16:     re.compile(r"\bdoublets?\b", re.IGNORECASE),
  17:     re.compile(r"\bdebris\b", re.IGNORECASE),
  18:     re.compile(r"\bnull\b", re.IGNORECASE),
  19:     # Match "na" and "n/a" as whole tokens
  20:     re.compile(r"\bn/?a\b", re.IGNORECASE),
  21: ]
  22: 
  23: 
  24: def should_abstain(query: str) -> Tuple[bool, str | None]:
  25:     """Return (True, reason) if query is a no-value indicator.
  26: 
  27:     Triggers include: unknown, doublet(s), debris, null, na, n/a (case-insensitive).
  28:     """
  29:     text = (query or "").strip()
  30:     for pat in _ABSTAIN_PATTERNS:
  31:         if pat.search(text):
  32:             return True, f"Query contains no-value indicator matching '{pat.pattern}'"
  33:     return False, None
  34: 
  35: 
  36: def context_violation(label_blob: str, tissue: str | None) -> bool:
  37:     """Detect anatomical incompatibilities given tissue context.
  38:     Conservative, token-based checks to avoid cross-system leakage.
  39:     """
  40:     t = (tissue or "").lower()
  41:     x = (label_blob or "").lower()
  42: 
  43:     # Brain region conflicts (expanded cortical detection)
  44:     cortical_tokens = [
  45:         "cortex", "cortical", "neocortex", "gyrus", "sulcus",
  46:         "temporal gyrus", "temporal cortex", "frontal lobe", "parietal lobe",
  47:         "occipital lobe", "temporal lobe", "entorhinal", "hippocampus",
  48:         "amygdala", "cingulate", "prefrontal", "neocortical",
  49:     ]
  50:     subcortical_striatal = ["striatal", "striatum", "basal ganglia", "putamen", "caudate", "globus pallidus", "substantia nigra"]
  51:     cerebellar_tokens = ["cerebellum", "cerebellar", "purkinje"]
  52: 
  53:     is_cortical = any(tok in t for tok in cortical_tokens)
  54:     is_striatal = any(tok in t for tok in subcortical_striatal)
  55:     is_cerebellar = any(tok in t for tok in cerebellar_tokens)
  56: 
  57:     if is_cortical and (any(tok in x for tok in subcortical_striatal) or any(tok in x for tok in cerebellar_tokens)):
  58:         return True
  59:     if is_striatal and ("cortical" in x or "cortex" in x or "gyrus" in x or "neocortex" in x or "hippocampus" in x or "amygdala" in x):
  60:         return True
  61:     if is_cerebellar and ("cortex" in x or "cortical" in x or "striatal" in x or "striatum" in x or "basal ganglia" in x):
  62:         return True
  63: 
  64:     # Organ-specific conflicts
  65:     if "lung" not in t and any(tok in x for tok in ["alveolar", "bronchial", "airway", "pulmonary"]):
  66:         return True
  67:     if "kidney" not in t and "renal" in x:
  68:         return True
  69: 
  70:     return False
  71: 
  72: 
  73: def species_violation(label_blob: str, organism: str | None) -> bool:
  74:     """Detect species incompatibilities based on label/definition markers.
  75: 
  76:     Heuristics:
  77:       - Reject cross-markers like (Mmus) vs (Hsap) when organism disagrees.
  78:       - Reject explicit species tokens in labels ("human", "mouse", etc.) when they disagree.
  79:     """
  80:     x = (label_blob or "").lower()
  81:     org = (organism or "").lower()
  82:     # Curated markers
  83:     if org.startswith("homo sapiens") and "(mmus" in x:
  84:         return True
  85:     if org.startswith("mus musculus") and "(hsap" in x:
  86:         return True
  87:     # Token-based species words
  88:     if org.startswith("homo sapiens"):
  89:         if re.search(r"\b(mouse|mus\s+musculus|murine|rat|rattus|zebrafish|danio\s+rerio|drosophila|fruit\s+fly|fly|caenorhabditis|c\.?\s*elegans|nematode)\b", x):
  90:             return True
  91:     if org.startswith("mus musculus"):
  92:         if re.search(r"\b(human|homo\s+sapiens)\b", x):
  93:             return True
  94:     return False
  95: 
  96: 
  97: # -----------------
  98: # Normalizers
  99: # -----------------
 100: 
 101: _ORG_CANONICAL = {
 102:     "homo sapiens": "Homo sapiens",
 103:     "human": "Homo sapiens",
 104:     "hs": "Homo sapiens",
 105:     "hsa": "Homo sapiens",
 106:     "hg": "Homo sapiens",
 107: 
 108:     "mus musculus": "Mus musculus",
 109:     "mouse": "Mus musculus",
 110:     "mice": "Mus musculus",
 111:     "mm": "Mus musculus",
 112:     "mmu": "Mus musculus",
 113: 
 114:     "danio rerio": "Danio rerio",
 115:     "zebrafish": "Danio rerio",
 116:     "dr": "Danio rerio",
 117:     "zfish": "Danio rerio",
 118: 
 119:     "drosophila melanogaster": "Drosophila melanogaster",
 120:     "fruit fly": "Drosophila melanogaster",
 121:     "fly": "Drosophila melanogaster",
 122:     "dm": "Drosophila melanogaster",
 123:     "dmel": "Drosophila melanogaster",
 124: 
 125:     "caenorhabditis elegans": "Caenorhabditis elegans",
 126:     "c. elegans": "Caenorhabditis elegans",
 127:     "worm": "Caenorhabditis elegans",
 128:     "cel": "Caenorhabditis elegans",
 129:     "ce": "Caenorhabditis elegans",
 130: }
 131: 
 132: 
 133: def normalize_organism(name: str | None) -> str | None:
 134:     if not name:
 135:         return name
 136:     key = name.strip().lower()
 137:     return _ORG_CANONICAL.get(key, name)
 138: 
 139: 
 140: # Require token to start with a letter to avoid matching bare numerics like "5+"
 141: _MARKER_SUFFIX_RE = re.compile(r"\b([A-Za-z][A-Za-z0-9-]*)([+-])\b")
 142: 
 143: 
 144: def normalize_marker_suffixes(text: str | None) -> str | None:
 145:     """Normalize marker suffixes like `CD25+` -> `CD25 positive`, `CD14-` -> `CD14 negative`.
 146:     Leaves other text unchanged. Returns unchanged when input is falsy.
 147:     """
 148:     if not text:
 149:         return text
 150:     def _sub(m: re.Match[str]) -> str:
 151:         token = m.group(1)
 152:         sign = m.group(2)
 153:         return f"{token} {'positive' if sign == '+' else 'negative'}"
 154:     out = _MARKER_SUFFIX_RE.sub(_sub, text)
 155:     # Ensure a space after the inserted positive/negative if next token is alnum (handles CD4+CD8+ -> CD4 positive CD8+)
 156:     out = re.sub(r"\b(positive|negative)(?=[A-Za-z0-9])", r"\1 ", out)
 157:     return out
 158: 
 159: 
 160: # Field name normalization
 161: _FIELD_CANONICAL = {
 162:     "cell_type": "cell_type",
 163:     "celltype": "cell_type",
 164:     "cell": "cell_type",
 165:     "tissue": "tissue",
 166:     "organ": "tissue",
 167:     "disease": "disease",
 168:     "condition": "disease",
 169:     "pathology": "disease",
 170:     "development_stage": "development_stage",
 171:     "dev_stage": "development_stage",
 172:     "development-stage": "development_stage",
 173:     "stage": "development_stage",
 174:     "sex": "sex",
 175:     "gender": "sex",
 176:     "self_reported_ethnicity": "self_reported_ethnicity",
 177:     "ethnicity": "self_reported_ethnicity",
 178:     "race": "self_reported_ethnicity",
 179:     "assay": "assay",
 180:     "assay_type": "assay",
 181:     "protocol": "assay",
 182:     "organism": "organism",
 183:     "species": "organism",
 184: }
 185: 
 186: 
 187: def normalize_field_name(name: str | None) -> str | None:
 188:     if not name:
 189:         return name
 190:     key = name.strip().lower()
 191:     return _FIELD_CANONICAL.get(key, name)

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/runtime_env.py
Size: 14 lines
================================================================================
   1: import os
   2: 
   3: def configure_runtime() -> None:
   4:     """Set safe defaults for OpenMP to avoid multi-runtime conflicts.
   5: 
   6:     Applies only if not already set by the environment. Keeps changes minimal
   7:     and portable across Linux, macOS Intel, and Apple Silicon.
   8:     """
   9:     if "KMP_DUPLICATE_LIB_OK" not in os.environ:
  10:         os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
  11:     if "OMP_NUM_THREADS" not in os.environ:
  12:         os.environ["OMP_NUM_THREADS"] = "1"
  13: 
  14: 

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/schema_policies.py
Size: 133 lines
================================================================================
   1: from typing import List, Optional, Dict
   2: 
   3: # Field -> default ontology_id set (broad)
   4: FIELD_TO_ONTOLOGIES = {
   5:     "cell_type": ["cl", "fbbt", "zfa", "wbbt"],
   6:     "tissue": ["uberon", "fbbt", "zfa", "wbbt"],
   7:     "disease": ["mondo", "pato"],  # PATO:0000461 used for healthy
   8:     "development_stage": ["hsapdv", "mmusdv", "fbdv", "wbls", "zfa"],
   9:     "sex": ["pato"],
  10:     "self_reported_ethnicity": ["hancestro"],
  11:     "assay": ["efo"],
  12:     "organism": ["ncbitaxon"],
  13: }
  14: 
  15: # Field -> Primary Ontology for boosting
  16: FIELD_TO_PRIMARY_ONTOLOGY: Dict[str, str] = {
  17:     "cell_type": "cl",
  18:     "tissue": "uberon",
  19:     "disease": "mondo",
  20:     "sex": "pato",
  21:     "self_reported_ethnicity": "hancestro",
  22:     "assay": "efo",
  23:     "organism": "ncbitaxon",
  24:     # development_stage is organism-dependent via SPECIES_ROUTING
  25: }
  26: 
  27: # Ontology ID -> expected CURIE prefix mapping (guardrail for malformed DB rows)
  28: ONTOLOGY_CURIE_PREFIX: Dict[str, str] = {
  29:     "cl": "CL:",
  30:     "uberon": "UBERON:",
  31:     "mondo": "MONDO:",
  32:     "pato": "PATO:",
  33:     "efo": "EFO:",
  34:     "ncbitaxon": "NCBITaxon:",
  35:     "fbbt": "FBbt:",
  36:     "zfa": "ZFA:",
  37:     "wbbt": "WBbt:",
  38:     "hsapdv": "HsapDv:",
  39:     "mmusdv": "MmusDv:",
  40:     "fbdv": "FBdv:",
  41:     "wbls": "WBls:",
  42:     "hancestro": "HANCESTRO:",
  43: }
  44: 
  45: # Species-aware overrides for field -> ontology_id set
  46: SPECIES_ROUTING = {
  47:     # human
  48:     "NCBITaxon:9606": {
  49:         "cell_type": ["cl"],
  50:         "development_stage": ["hsapdv"],
  51:         "tissue": ["uberon"],
  52:     },
  53:     # mouse
  54:     "NCBITaxon:10090": {
  55:         "cell_type": ["cl"],
  56:         "development_stage": ["mmusdv"],
  57:         "tissue": ["uberon"],
  58:     },
  59:     # zebrafish
  60:     "NCBITaxon:7955": {
  61:         "cell_type": ["cl", "zfa"],
  62:         "development_stage": ["zfa"],
  63:         "tissue": ["uberon", "zfa"],
  64:     },
  65:     # fruit fly
  66:     "NCBITaxon:7227": {
  67:         "cell_type": ["cl", "fbbt"],
  68:         "development_stage": ["fbdv"],
  69:         "tissue": ["uberon", "fbbt"],
  70:     },
  71:     # C. elegans
  72:     "NCBITaxon:6239": {
  73:         "cell_type": ["cl", "wbbt"],
  74:         "development_stage": ["wbls"],
  75:         "tissue": ["uberon", "wbbt"],
  76:     },
  77: }
  78: 
  79: # Supported organisms (canonical names only)
  80: SUPPORTED_ORGANISMS = {
  81:     "Homo sapiens": "NCBITaxon:9606",
  82:     "Mus musculus": "NCBITaxon:10090",
  83:     "Danio rerio": "NCBITaxon:7955",
  84:     "Drosophila melanogaster": "NCBITaxon:7227",
  85:     "Caenorhabditis elegans": "NCBITaxon:6239",
  86: }
  87: 
  88: def supported_organisms() -> List[str]:
  89:     return list(SUPPORTED_ORGANISMS.keys())
  90: 
  91: def _canonical_taxon(organism: Optional[str]) -> Optional[str]:
  92:     if not organism:
  93:         return None
  94:     # Enforce exact match to supported names only
  95:     try:
  96:         return SUPPORTED_ORGANISMS[organism]
  97:     except KeyError:
  98:         raise ValueError(
  99:             "Unsupported organism. Use one of: " + ", ".join(supported_organisms())
 100:         )
 101: 
 102: def supported_fields() -> List[str]:
 103:     return list(FIELD_TO_ONTOLOGIES.keys())
 104: 
 105: def allowed_ontologies_for(field_name: Optional[str], organism: Optional[str]) -> Optional[List[str]]:
 106:     """Return ontology_id list for this field and organism, or None if no restriction.
 107:     If field_name is provided and not supported, raises ValueError with a helpful message.
 108:     """
 109:     if not field_name:
 110:         return None
 111:     field = field_name.strip().lower()
 112:     base = FIELD_TO_ONTOLOGIES.get(field)
 113:     if not base:
 114:         raise ValueError("Unsupported field. Use one of: " + ", ".join(supported_fields()))
 115:     tax = _canonical_taxon(organism)
 116:     if tax and tax in SPECIES_ROUTING and field in SPECIES_ROUTING[tax]:
 117:         return SPECIES_ROUTING[tax][field]
 118:     return base
 119: 
 120: def get_ontology_prior_for_field(field_name: str) -> Optional[str]:
 121:     """Returns the primary ontology source for a given field."""
 122:     if not field_name:
 123:         return None
 124:     return FIELD_TO_PRIMARY_ONTOLOGY.get(field_name.lower().strip())
 125: 
 126: def allowed_curie_prefixes(ontology_ids: Optional[List[str]]) -> Optional[List[str]]:
 127:     """Return list of CURIE prefixes corresponding to ontology_ids.
 128:     If unknown ontology id is provided, it is ignored.
 129:     """
 130:     if not ontology_ids:
 131:         return None
 132:     prefixes = [ONTOLOGY_CURIE_PREFIX[o] for o in ontology_ids if o in ONTOLOGY_CURIE_PREFIX]
 133:     return prefixes or None

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/server.py
Size: 243 lines
================================================================================
   1: from fastapi import FastAPI, HTTPException, Depends, Header
   2: from typing import Any, Dict
   3: import os
   4: import threading
   5: from datetime import datetime
   6: 
   7: # Load environment variables from .env file
   8: try:
   9:     from dotenv import load_dotenv
  10:     load_dotenv()
  11: except ImportError:
  12:     # Fallback if python-dotenv is not available
  13:     pass
  14: from .runtime_env import configure_runtime
  15: from . import __version__
  16: from .config import BondSettings
  17: from .pipeline import BondMatcher
  18: from .models import (
  19:     QueryItem, ErrorResponse
  20: )
  21: from .logger import logger
  22: from .rules import normalize_field_name, normalize_organism
  23: 
  24: configure_runtime()
  25: app = FastAPI(title="BOND API", version=__version__)
  26: settings = BondSettings()
  27: _matcher_lock = threading.Lock()
  28: matcher = None  # Lazy initialization
  29: 
  30: def verify_api_key(authorization: str = Header(None)):
  31:     """Basic API key authentication via static token.
  32:     - Set BOND_API_KEY to any secret string to require clients to send 'Authorization: Bearer <BOND_API_KEY>'.
  33:     - For local/dev without auth, set BOND_ALLOW_ANON=1.
  34:     """
  35:     api_key = os.getenv("BOND_API_KEY")
  36:     if not api_key:
  37:         if os.getenv("BOND_ALLOW_ANON", "0").lower() in ("1", "true", "yes"):
  38:             return True
  39:         raise HTTPException(
  40:             status_code=401,
  41:             detail="BOND_API_KEY not set. Set BOND_API_KEY or BOND_ALLOW_ANON=1 for local development."
  42:         )
  43:     if not authorization or not authorization.startswith("Bearer "):
  44:         raise HTTPException(status_code=401, detail="Missing Authorization header. Use 'Authorization: Bearer <BOND_API_KEY>'")
  45:     if authorization[len("Bearer "):].strip() != api_key:
  46:         raise HTTPException(status_code=401, detail="Invalid API key. Check your BOND_API_KEY env variable")
  47:     return True
  48: 
  49: def get_matcher():
  50:     """Lazy initialization of the matcher to prevent crashes on missing assets"""
  51:     global matcher
  52:     if matcher is None:
  53:         with _matcher_lock:
  54:             if matcher is None:
  55:                 try:
  56:                     matcher = BondMatcher(settings)
  57:                 except Exception as e:
  58:                     raise HTTPException(
  59:                         status_code=503,
  60:                         detail=f"BOND matcher initialization failed: {str(e)}. Ensure assets exist (ontologies.sqlite) and build the FAISS store with 'bond-build-faiss'."
  61:                     )
  62:     return matcher
  63: 
  64: # Models are now imported from bond.models
  65: 
  66: @app.get("/health")
  67: def health_check():
  68:     """Health check endpoint"""
  69:     return {
  70:         "status": "healthy",
  71:         "timestamp": datetime.now().isoformat(),
  72:         "service": "BOND API",
  73:         "version": __version__
  74:     }
  75: 
  76: @app.post("/query")
  77: def query(item: QueryItem, auth: bool = Depends(verify_api_key), verbose: bool = False) -> Dict[str, Any]:
  78:     try:
  79:         matcher = get_matcher()
  80:         # Normalize inputs at API boundary for consistency
  81:         field_name = normalize_field_name(item.field_name) or item.field_name
  82:         organism = normalize_organism(item.organism) or item.organism
  83:         # Treat common null-like strings as missing tissue context
  84:         tval = (item.tissue or "").strip().lower()
  85:         tissue = None if tval in {"", "null", "none", "n/a", "na"} else item.tissue
  86:         result = matcher.query(
  87:             item.query,
  88:             field_name=field_name,
  89:             organism=organism,
  90:             tissue=tissue,
  91:             n_expansions=item.n_expansions,
  92:             topk_final=item.topk_final,
  93:             num_choices=item.num_choices,
  94:             topk_exact=item.topk_exact,
  95:             topk_bm25=item.topk_bm25,
  96:             topk_dense=item.topk_dense,
  97:             rrf_k=item.rrf_k,
  98:             exact_only=item.exact_only or False,
  99:             graph_depth=item.graph_depth,
 100:             rerank_after_graph=item.rerank_after_graph if item.rerank_after_graph is not None else True,
 101:             # Always compute trace for consistent internal flow; we can drop it in the response
 102:             return_trace=True,
 103:         )
 104:         # Standardized JSON output
 105:         def _chosen_clean(ch):
 106:             if not ch:
 107:                 return None
 108:             return {
 109:                 "id": ch.get("id"),
 110:                 "label": ch.get("label"),
 111:                 "definition": ch.get("definition"),
 112:                 "source": ch.get("source"),
 113:                 "iri": ch.get("iri"),
 114:                 "synonyms_exact": ch.get("synonyms_exact"),
 115:                 "synonyms_related": ch.get("synonyms_related"),
 116:                 "synonyms_broad": ch.get("synonyms_broad"),
 117:                 "synonyms_generic": ch.get("synonyms_generic"),
 118:                 "alt_ids": ch.get("alt_ids"),
 119:                 "xrefs": ch.get("xrefs"),
 120:                 "namespace": ch.get("namespace"),
 121:                 "subsets": ch.get("subsets"),
 122:                 "comments": ch.get("comments"),
 123:                 "parents_is_a": ch.get("parents_is_a"),
 124:                 "abstracts": ch.get("abstracts"),
 125:             }
 126:         chosen = _chosen_clean(result.get("chosen"))
 127:         if item.return_trace or verbose:
 128:             return {
 129:                 "expansions": result.get("trace", {}).get("expansions", []),
 130:                 "context_terms": result.get("trace", {}).get("context_terms", []),
 131:                 "fusion_top_k": result.get("trace", {}).get("fusion", []),
 132:                 "trace": result.get("trace", {}),
 133:                 "results": result.get("results", []),
 134:                 "disambiguation": {
 135:                     **(chosen or {}),
 136:                     "reason": (result.get("chosen") or {}).get("reason"),
 137:                     "retrieval_confidence": (result.get("chosen") or {}).get("retrieval_confidence"),
 138:                     "llm_confidence": (result.get("chosen") or {}).get("llm_confidence"),
 139:                 },
 140:                 "alternatives": result.get("alternatives", []),
 141:             }
 142:         else:
 143:             payload = {
 144:                 **(chosen or {}),
 145:                 "reason": (result.get("chosen") or {}).get("reason"),
 146:                 "retrieval_confidence": (result.get("chosen") or {}).get("retrieval_confidence"),
 147:                 "llm_confidence": (result.get("chosen") or {}).get("llm_confidence"),
 148:             }
 149:             if item.num_choices and item.num_choices > 0:
 150:                 payload["alternatives"] = result.get("alternatives", [])
 151:             return payload
 152:     except ValueError as ve:
 153:         # Map user errors (e.g., unsupported field/organism) to 400 with helpful context
 154:         try:
 155:             from .schema_policies import supported_organisms, supported_fields
 156:             detail: Dict[str, Any] = {
 157:                 "error": "Invalid input",
 158:                 "detail": str(ve),
 159:                 "supported_organisms": supported_organisms(),
 160:                 "supported_fields": supported_fields(),
 161:                 "timestamp": datetime.now().isoformat(),
 162:             }
 163:         except Exception:
 164:             detail = {"error": "Invalid input", "detail": str(ve), "timestamp": datetime.now().isoformat()}
 165:         raise HTTPException(status_code=400, detail=detail)
 166:     except Exception as e:
 167:         raise HTTPException(
 168:             status_code=500,
 169:             detail={
 170:                 "error": "Query processing failed",
 171:                 "detail": str(e),
 172:                 "timestamp": datetime.now().isoformat(),
 173:             },
 174:         )
 175: 
 176: # Batch processing is not supported by this API
 177: 
 178: @app.get("/config")
 179: def get_config(auth: bool = Depends(verify_api_key)) -> Dict[str, Any]:
 180:     try:
 181:         matcher = get_matcher()
 182:         config_dict = matcher.cfg.model_dump()
 183:         return config_dict
 184:     except ValueError as ve:
 185:         from .schema_policies import supported_organisms, supported_fields
 186:         raise HTTPException(status_code=400, detail={
 187:             "error": str(ve),
 188:             "supported_organisms": supported_organisms(),
 189:             "supported_fields": supported_fields(),
 190:         })
 191:     except Exception as e:
 192:         raise HTTPException(status_code=503, detail=str(e))
 193: 
 194: @app.get("/ontologies")
 195: def get_ontologies(auth: bool = Depends(verify_api_key)) -> Dict[str, Any]:
 196:     """Returns information about available ontologies in the index."""
 197:     try:
 198:         matcher = get_matcher()
 199:         sources = matcher.get_available_ontologies()
 200: 
 201:         # Get total term count
 202:         cur = matcher.get_connection().cursor()
 203:         cur.execute(f"SELECT COUNT(*) FROM {matcher.cfg.table_terms}")
 204:         total_terms = cur.fetchone()[0]
 205: 
 206:         return {"sources": sources, "total_terms": total_terms, "last_updated": None}
 207:     except Exception as e:
 208:         raise HTTPException(status_code=503, detail=str(e))
 209: 
 210: @app.get("/organisms")
 211: def list_organisms(auth: bool = Depends(verify_api_key)) -> Dict[str, Any]:
 212:     from .schema_policies import supported_organisms
 213:     return {"organisms": supported_organisms()}
 214: 
 215: @app.get("/fields")
 216: def list_fields(auth: bool = Depends(verify_api_key)) -> Dict[str, Any]:
 217:     from .schema_policies import supported_fields
 218:     return {"fields": supported_fields()}
 219: 
 220: # Cache endpoints are not exposed
 221: 
 222: # GPU status endpoint is not exposed
 223: 
 224: @app.get("/metrics")
 225: def get_metrics(auth: bool = Depends(verify_api_key)) -> Dict[str, Any]:
 226:     """Get basic metrics for monitoring"""
 227:     try:
 228:         matcher = get_matcher()
 229:         return {
 230:             "cache": {"cache_size": 0, "cache_hits": 0, "cache_misses": 0, "hit_rate": 0.0},
 231:             "gpu": matcher.faiss.get_gpu_status() if hasattr(matcher, 'faiss') else {},
 232:             "uptime_seconds": (datetime.now() - matcher._start_time).total_seconds() if hasattr(matcher, '_start_time') else None,
 233:             "request_count": getattr(matcher, '_request_count', 0),
 234:             "start_time": matcher._start_time.isoformat() if hasattr(matcher, '_start_time') else None
 235:         }
 236:     except Exception as e:
 237:         logger.error(f"Failed to get metrics: {e}")
 238:         return {"error": str(e)}
 239: 
 240: def main():
 241:     import uvicorn
 242:     logger.info("Starting BOND API server...")
 243:     uvicorn.run(app, host="0.0.0.0", port=8000)

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/validate_signature.py
Size: 28 lines
================================================================================
   1: import json
   2: import os
   3: import numpy as np
   4: from typing import Callable
   5: from .logger import logger
   6: 
   7: def cosine(a: np.ndarray, b: np.ndarray) -> float:
   8:     return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-9))
   9: 
  10: def validate_embedding_signature(signature_path: str, embed_fn: Callable[[list], list], threshold: float = 0.999):
  11:     if not os.path.exists(signature_path):
  12:         raise FileNotFoundError(f"Embedding signature not found at {signature_path}. Please run the build script.")
  13:     with open(signature_path, "r", encoding="utf-8") as f:
  14:         sig = json.load(f)
  15: 
  16:     anchor_text = sig["anchor_text"]
  17:     anchor_vec = np.array(sig["anchor_vector"], dtype=np.float32)
  18:     test_vec = np.array(embed_fn([anchor_text])[0], dtype=np.float32)
  19: 
  20:     sim = cosine(anchor_vec, test_vec)
  21:     if sim < threshold:
  22:         raise RuntimeError(
  23:             f"Embedding mismatch detected! The loaded model '{sig.get('model_id', 'unknown')}' "
  24:             f"does not match the index signature. Cosine similarity was {sim:.6f} (threshold: {threshold}). "
  25:             "Ensure you are using the correct model or rebuild the index with `bond-build-faiss`."
  26:         )
  27:     logger.info("Embedding signature validated successfully.")
  28:     return True

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/retrieval/__init__.py
Size: 1 lines
================================================================================
   1: # Retrieval package for BOND

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/retrieval/bm25_sqlite.py
Size: 107 lines
================================================================================
   1: import sqlite3
   2: from typing import List, Dict, Optional
   3: 
   4: def _escape_fts_phrase(s: str) -> str:
   5:     return s.replace('"', '""')
   6: 
   7: def search_exact(
   8:     conn: sqlite3.Connection,
   9:     table_terms: str,
  10:     table_fts: str,
  11:     q_norms: List[str],
  12:     k: int,
  13:     sources: Optional[List[str]] = None,
  14: ) -> List[Dict]:
  15:     """Exact match via FTS over the provided FTS table (label + synonyms_*).
  16: 
  17:     Args:
  18:         conn: Open SQLite connection
  19:         table_terms: Name of the base terms table (content source for FTS)
  20:         table_fts: Name of the FTS virtual table (should mirror text columns)
  21:         q_norms: Normalized exact phrases to match
  22:         k: Max results per phrase (deduplicated overall)
  23:         sources: Optional ontology_id filter
  24:     Returns:
  25:         List of dicts with keys: {id, label}
  26:     """
  27:     cur = conn.cursor()
  28:     if isinstance(q_norms, str):
  29:         q_norms = [q_norms]
  30:     if not q_norms:
  31:         return []
  32: 
  33:     clauses = []
  34:     for q in q_norms:
  35:         p = _escape_fts_phrase(q)
  36:         clauses.append(
  37:             f"(label:\"{p}\" OR synonyms_exact:\"{p}\" OR synonyms_related:\"{p}\" OR synonyms_broad:\"{p}\" OR synonyms_narrow:\"{p}\")"
  38:         )
  39:     match_expr = " OR ".join(clauses)
  40: 
  41:     base = (
  42:         f"SELECT t.curie, t.label, t.ontology_id FROM {table_fts} "
  43:         f"JOIN {table_terms} t ON t.rowid = {table_fts}.rowid "
  44:         f"WHERE {table_fts} MATCH ?"
  45:     )
  46:     params: List = [match_expr]
  47:     if sources:
  48:         placeholders = ",".join("?" for _ in sources)
  49:         base += f" AND t.ontology_id IN ({placeholders})"
  50:         params.extend(sources)
  51: 
  52:     try:
  53:         base += f" ORDER BY bm25({table_fts}) ASC LIMIT ?"
  54:         params.append(k * len(q_norms))
  55:         rows = cur.execute(base, params).fetchall()
  56:     except sqlite3.OperationalError:
  57:         rows = cur.execute(base + " LIMIT ?", params + [k * len(q_norms)]).fetchall()
  58: 
  59:     out = []
  60:     seen = set()
  61:     for curie, label, _src in rows:
  62:         if curie not in seen:
  63:             seen.add(curie)
  64:             out.append({"id": curie, "label": label})
  65:     return out[: k * len(q_norms)]
  66: 
  67: def search_bm25(conn: sqlite3.Connection, table_terms: str, table_fts: str, q: str, k: int, sources: Optional[List[str]] = None) -> List[Dict]:
  68:     """BM25 over ontology_terms_fts only."""
  69:     cur = conn.cursor()
  70:     match_param = '"' + q.replace('"', '""') + '"'
  71:     base_query = (
  72:         f"SELECT t.curie, t.label, t.definition, t.ontology_id "
  73:         f"FROM {table_fts} JOIN {table_terms} t ON t.rowid = {table_fts}.rowid "
  74:         f"WHERE {table_fts} MATCH ?"
  75:     )
  76:     params = [match_param]
  77:     if sources:
  78:         placeholders = ",".join("?" for _ in sources)
  79:         base_query += f" AND t.ontology_id IN ({placeholders})"
  80:         params.extend(sources)
  81: 
  82:     try:
  83:         base_query += f" ORDER BY bm25({table_fts}) ASC LIMIT ?"
  84:         params.append(k)
  85:         cur.execute(base_query, params)
  86:     except sqlite3.OperationalError:
  87:         base_query = base_query.replace(f"ORDER BY bm25({table_fts}) ASC", "ORDER BY length(t.label) ASC")
  88:         cur.execute(base_query, params)
  89: 
  90:     results = []
  91:     for row in cur.fetchall():
  92:         results.append({
  93:             "id": row[0],
  94:             "label": row[1],
  95:             "def": row[2],
  96:             "source": row[3],
  97:         })
  98:     return results
  99: """SQLite FTS retrieval helpers for BOND.
 100: 
 101: This module exposes two retrieval channels over the text index:
 102:   - search_exact: phrase-style matching against label and synonym columns
 103:   - search_bm25: BM25-ranked retrieval over the same FTS virtual table
 104: 
 105: Both functions accept the base terms table and the FTS table names, and support
 106: optional ontology_id scoping via the `sources` parameter.
 107: """

================================================================================

File: /Users/rajlq7/Downloads/Terms/BOND/bond/retrieval/faiss_store.py
Size: 131 lines
================================================================================
   1: import os
   2: import numpy as np
   3: import faiss
   4: import logging
   5: from typing import List
   6: import threading
   7: 
   8: logger = logging.getLogger(__name__)
   9: 
  10: def _profile_dir(assets_path: str) -> str:
  11:     """Return path to the single FAISS store directory."""
  12:     return os.path.join(assets_path, "faiss_store")
  13: 
  14: class FaissStore:
  15:     def __init__(self, assets_path: str, rescore_multiplier: int = 20):
  16:         self.profile_path = _profile_dir(assets_path)
  17:         self.rescore_multiplier = rescore_multiplier
  18: 
  19:         if not os.path.isdir(self.profile_path):
  20:             raise FileNotFoundError(f"FAISS store directory not found: {self.profile_path}")
  21: 
  22:         faiss_path = os.path.join(self.profile_path, "embeddings.faiss")
  23:         id_map_path = os.path.join(self.profile_path, "id_map.npy")
  24:         self.signature_path = os.path.join(self.profile_path, "embedding_signature.json")
  25: 
  26:         logger.info("Loading FAISS index (binary + int8 rescoring)...")
  27: 
  28:         # Load the binary index and the separate int8 rescore vectors
  29:         self.base_index = faiss.read_index_binary(faiss_path)
  30:         rescore_path = os.path.join(self.profile_path, "rescore_vectors.npy")
  31:         self.rescore_vectors = np.load(rescore_path, mmap_mode="r")
  32: 
  33:         self.index = self.base_index
  34:         # Memory-map id_map to avoid loading entire array into RAM at import
  35:         self.id_map = np.load(id_map_path, allow_pickle=False, mmap_mode="r")
  36:         self._search_lock = threading.Lock()
  37:         self._id_to_index = None  # lazily constructed reverse map
  38: 
  39:     @staticmethod
  40:     def _float_to_binary_packbits(vectors: np.ndarray) -> np.ndarray:
  41:         """Helper used in tests to validate binary packing logic."""
  42:         if vectors.ndim == 1:
  43:             vectors = vectors.reshape(1, -1)
  44:         return np.packbits((vectors >= 0).astype(np.uint8), axis=-1)
  45: 
  46:     def get_gpu_status(self) -> dict:
  47:         """GPU acceleration is not applicable for binary index; always CPU."""
  48:         return {"gpu_requested": False, "gpu_available": False, "gpu_active": False}
  49: 
  50:     def close(self):
  51:         """No-op for CPU-only binary index"""
  52:         return None
  53: 
  54:     def __del__(self):
  55:         """Cleanup on deletion"""
  56:         self.close()
  57: 
  58:     def search(self, vectors: np.ndarray, k: int) -> List[List[str]]:
  59:         if vectors.ndim == 1:
  60:             vectors = vectors.reshape(1, -1)
  61: 
  62:         n_queries = vectors.shape[0]
  63:         all_results = []
  64: 
  65:         # Stage 1: Fast binary search for a large number of candidates
  66:         k_rescore = k * self.rescore_multiplier
  67:         q_bin = np.packbits(np.where(vectors >= 0, 1, 0), axis=-1)
  68:         # Guard FAISS calls with a lock for thread-safety across profiles/builds
  69:         with self._search_lock:
  70:             _, initial_indices = self.index.search(q_bin, k_rescore)
  71: 
  72:         for query_idx in range(n_queries):
  73:             cand_indices = initial_indices[query_idx]
  74:             cand_indices = cand_indices[cand_indices != -1]
  75:             if len(cand_indices) == 0:
  76:                 all_results.append([])
  77:                 continue
  78: 
  79:             # Stage 2: Precise rescoring with int8 vectors
  80:             cand_vecs_int8 = self.rescore_vectors[cand_indices]
  81:             query_vector_fp32 = vectors[query_idx]
  82: 
  83:             cand_vecs_fp32 = cand_vecs_int8.astype(np.float32) / 127.0
  84:             scores = np.dot(cand_vecs_fp32, query_vector_fp32.T).squeeze()
  85: 
  86:             final_idx_indices = np.argsort(-scores)[:k]
  87:             final_indices = cand_indices[final_idx_indices]
  88:             all_results.append([str(self.id_map[i]) for i in final_indices])
  89: 
  90:         return all_results
  91: 
  92:     def _ensure_reverse_map(self):
  93:         """Build a reverse map from ID string -> index into rescore/id_map arrays."""
  94:         if self._id_to_index is None:
  95:             # Convert to Python str to ensure consistent keys
  96:             mapping = {}
  97:             for i in range(self.id_map.shape[0]):
  98:                 try:
  99:                     k = str(self.id_map[i])
 100:                     mapping[k] = i
 101:                 except Exception:
 102:                     continue
 103:             self._id_to_index = mapping
 104: 
 105:     def score_ids(self, query_vector: np.ndarray, ids: List[str]) -> dict:
 106:         """Compute cosine-like scores between a single query vector and candidate IDs.
 107: 
 108:         Uses the precomputed int8 rescore vectors; no term re-embedding.
 109:         Returns a dict {id: score} for the provided ids that exist in the index.
 110:         """
 111:         if query_vector.ndim != 1:
 112:             # Flatten any 2D of shape (1, d)
 113:             query_vector = query_vector.reshape(-1)
 114:         self._ensure_reverse_map()
 115:         if not ids:
 116:             return {}
 117:         # Collect available indices
 118:         idxs = []
 119:         keep_ids = []
 120:         for _id in ids:
 121:             j = self._id_to_index.get(str(_id)) if self._id_to_index else None
 122:             if j is not None:
 123:                 idxs.append(j)
 124:                 keep_ids.append(str(_id))
 125:         if not idxs:
 126:             return {}
 127:         cand_vecs_int8 = self.rescore_vectors[idxs]
 128:         cand_vecs_fp32 = cand_vecs_int8.astype(np.float32) / 127.0
 129:         # Dot product equals cosine similarity when both sides are normalized
 130:         scores = cand_vecs_fp32 @ query_vector.astype(np.float32)
 131:         return {k: float(v) for k, v in zip(keep_ids, scores.tolist())}

================================================================================

SUMMARY
--------------------------------------------------------------------------------
Total files found: 22
Text files processed: 22
Documentation generated: 2025-08-31 01:29:47
